{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd09e5a8",
   "metadata": {},
   "source": [
    "### Pipelines:\n",
    "\n",
    "1. Idea of Composite Estimator:\n",
    "    One ore more transformers/estimators are connected together. Composits estimators could be realised with the halp of pipelines in Sklearn.\n",
    "    \n",
    "    The pipeline makes our code reusable and modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff693f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c514644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\DEVVRAK\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data = load_breast_cancer()\n",
    "cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c6b993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3a1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7a9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6c9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first pass data through imputer then Scaler and finally train the ML model and get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bc51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "model_list = [LogisticRegression(max_iter=500), DecisionTreeClassifier(), RandomForestClassifier(), SVC(C=100), KNeighborsClassifier(n_neighbors=7)]\n",
    "for model in model_list:\n",
    "    pipeline= make_pipeline(SimpleImputer(strategy='median'), RobustScaler(), model, verbose=True)\n",
    "    pipelines.append(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2544e5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('robustscaler', RobustScaler())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines[1].steps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbabb45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('decisiontreeclassifier', DecisionTreeClassifier())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines[1].steps[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c65bd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('svc', SVC(C=100))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines[3].steps[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b27973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines[1][2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5cb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer_data.data, cancer_data.target) # default 25 % test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d2d4d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing logisticregression, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing decisiontreeclassifier, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.2s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing svc, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing kneighborsclassifier, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "for pipeline in pipelines:\n",
    "    pipeline.fit(x_train, y_train)  # first it will go to imputer then scaler and then fith the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dbc341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965034965034965\n",
      "0.9230769230769231\n",
      "0.972027972027972\n",
      "0.9370629370629371\n",
      "0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "for pipeline in pipelines:\n",
    "    print(pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f706d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609862671660424\n",
      "0.9236371202663338\n",
      "0.9702455264253016\n",
      "0.9312317935913441\n",
      "0.9480857261756138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "for pipeline in pipelines:\n",
    "    print(recall_score(y_test, pipeline.predict(x_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36862935",
   "metadata": {},
   "source": [
    "### Cross Validation:\n",
    "\n",
    "The idea of only splitting data once for creating train test sets is flawed. Random presentation could easily give us high performance. So a better idea would be to use Cross Validation and report an averaged out metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a77fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f145d003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21e5d5226d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digits.images[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7b7be6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, min_samples_split=4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=7, min_samples_split=4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03c7a7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8266666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d39e5be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8789903489235338"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00825b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation:\n",
    "# Split data into k-folds\n",
    "# use random k-1 folds for training\n",
    "# use remaining fold for testing\n",
    "# run it for k times for a generalised behaviour\n",
    "\n",
    "from sklearn.model_selection import cross_val_score \n",
    "scores = cross_val_score(dt, digits.data, digits.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "961fa074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73888889, 0.65555556, 0.77715877, 0.77437326, 0.76880223])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9167b8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7429557412565769"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35b960da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045782705350179954"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bffee38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02098608, 0.01297188, 0.01297188, 0.01296043, 0.01396251]),\n",
       " 'score_time': array([0.00199032, 0.00199175, 0.0019896 , 0.00198674, 0.00195789]),\n",
       " 'test_precision_macro': array([0.76288013, 0.71585417, 0.78223394, 0.80642389, 0.77562027]),\n",
       " 'test_recall_macro': array([0.75564994, 0.68094595, 0.77035544, 0.78397469, 0.76279065]),\n",
       " 'test_accuracy': array([0.75555556, 0.68055556, 0.77158774, 0.78551532, 0.76044568])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validate: Get Scores for multiple metrics\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['precision_macro', 'recall_macro', 'accuracy']\n",
    "cross_validate(dt, digits.data, digits.target, scoring=scoring, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57aedc",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Hyperparameters: parameters which are user provided and control the algorithm itself\n",
    "THese are dependent on data and require multiple experiments(hit an trial) to acheive the best values\n",
    "\n",
    "Sklearn provides Grid Search to implement exhaustive search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55a065cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d289650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(dt, param_grid={'max_depth':range(5,30,5), 'min_samples_split':[2,3,4,5]}, cv=5, n_jobs=-1, scoring='recall_macro',verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f19675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': range(5, 30, 5),\n",
       "                         'min_samples_split': [2, 3, 4, 5]},\n",
       "             scoring='recall_macro', verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a41162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20, min_samples_split=4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid_search.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bf1f298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01835179, 0.0249332 , 0.0249321 , 0.01934481, 0.03311095,\n",
       "        0.02772584, 0.02892294, 0.03291125, 0.0325139 , 0.03251233,\n",
       "        0.03330903, 0.02912259, 0.0323102 , 0.02971792, 0.03331695,\n",
       "        0.0297194 , 0.03311009, 0.03191981, 0.03273926, 0.02752943]),\n",
       " 'std_fit_time': array([0.00149385, 0.00504623, 0.00403792, 0.00162605, 0.0091925 ,\n",
       "        0.00159602, 0.00362223, 0.01158122, 0.00161793, 0.00430376,\n",
       "        0.00119582, 0.00203534, 0.00544995, 0.00342028, 0.00525249,\n",
       "        0.00255386, 0.00443333, 0.00405174, 0.00518929, 0.0029546 ]),\n",
       " 'mean_score_time': array([0.00718012, 0.00638385, 0.00259323, 0.00279994, 0.00239449,\n",
       "        0.00259352, 0.00279255, 0.00239291, 0.00239263, 0.00279288,\n",
       "        0.00179482, 0.00319171, 0.00339093, 0.00218983, 0.00218706,\n",
       "        0.00259981, 0.00239387, 0.00269518, 0.0026721 , 0.00179563]),\n",
       " 'std_score_time': array([0.0021318 , 0.00293296, 0.00048809, 0.00075687, 0.00079689,\n",
       "        0.00079984, 0.00074685, 0.00049065, 0.00049245, 0.0007451 ,\n",
       "        0.00074674, 0.00097811, 0.00135296, 0.00038865, 0.00040226,\n",
       "        0.00119508, 0.00048938, 0.00074722, 0.00076783, 0.00039892]),\n",
       " 'param_max_depth': masked_array(data=[5, 5, 5, 5, 10, 10, 10, 10, 15, 15, 15, 15, 20, 20, 20,\n",
       "                    20, 25, 25, 25, 25],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3,\n",
       "                    4, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 10, 'min_samples_split': 2},\n",
       "  {'max_depth': 10, 'min_samples_split': 3},\n",
       "  {'max_depth': 10, 'min_samples_split': 4},\n",
       "  {'max_depth': 10, 'min_samples_split': 5},\n",
       "  {'max_depth': 15, 'min_samples_split': 2},\n",
       "  {'max_depth': 15, 'min_samples_split': 3},\n",
       "  {'max_depth': 15, 'min_samples_split': 4},\n",
       "  {'max_depth': 15, 'min_samples_split': 5},\n",
       "  {'max_depth': 20, 'min_samples_split': 2},\n",
       "  {'max_depth': 20, 'min_samples_split': 3},\n",
       "  {'max_depth': 20, 'min_samples_split': 4},\n",
       "  {'max_depth': 20, 'min_samples_split': 5},\n",
       "  {'max_depth': 25, 'min_samples_split': 2},\n",
       "  {'max_depth': 25, 'min_samples_split': 3},\n",
       "  {'max_depth': 25, 'min_samples_split': 4},\n",
       "  {'max_depth': 25, 'min_samples_split': 5}],\n",
       " 'split0_test_score': array([0.61699914, 0.63922136, 0.63644359, 0.61422136, 0.78660661,\n",
       "        0.77818962, 0.75072072, 0.75604676, 0.78383312, 0.78930502,\n",
       "        0.7781982 , 0.76144359, 0.77542042, 0.76414629, 0.77255899,\n",
       "        0.78660232, 0.77240455, 0.77271343, 0.76160232, 0.78953882]),\n",
       " 'split1_test_score': array([0.48975118, 0.49530674, 0.49245388, 0.49245388, 0.70372372,\n",
       "        0.70642643, 0.70928357, 0.71738739, 0.69184041, 0.72024453,\n",
       "        0.72826469, 0.71986057, 0.71716216, 0.73945517, 0.73374088,\n",
       "        0.71723295, 0.71152295, 0.71422565, 0.71445517, 0.72286787]),\n",
       " 'split2_test_score': array([0.6754714 , 0.67269362, 0.67824917, 0.66713806, 0.78981275,\n",
       "        0.78981275, 0.79814609, 0.79545663, 0.80696962, 0.80099894,\n",
       "        0.80378997, 0.79838456, 0.79569511, 0.79838456, 0.81203498,\n",
       "        0.78997615, 0.80934552, 0.78988783, 0.80101219, 0.80362657]),\n",
       " 'split3_test_score': array([0.73009653, 0.72183827, 0.7190562 , 0.72461604, 0.83801373,\n",
       "        0.83500644, 0.84875375, 0.83786787, 0.82134277, 0.83485628,\n",
       "        0.82366152, 0.8404955 , 0.8377885 , 0.82620978, 0.84033677,\n",
       "        0.83485628, 0.82358215, 0.83206993, 0.8404955 , 0.84319391]),\n",
       " 'split4_test_score': array([0.63457314, 0.63457314, 0.63179537, 0.63179537, 0.81704419,\n",
       "        0.8061583 , 0.81194766, 0.80616688, 0.78409052, 0.79497211,\n",
       "        0.79226941, 0.79219005, 0.7977456 , 0.80616688, 0.80624196,\n",
       "        0.79775418, 0.79520163, 0.79782497, 0.80323037, 0.78949163]),\n",
       " 'mean_test_score': array([0.62937828, 0.63272663, 0.63159964, 0.62604494, 0.7870402 ,\n",
       "        0.78311871, 0.78377036, 0.78258511, 0.77761529, 0.78807538,\n",
       "        0.78523676, 0.78247485, 0.78476236, 0.78687254, 0.79298271,\n",
       "        0.78528438, 0.78241136, 0.78134436, 0.78415911, 0.78974376]),\n",
       " 'std_test_score': array([0.07993084, 0.07545603, 0.07643281, 0.0767129 , 0.04571225,\n",
       "        0.0428345 , 0.04871144, 0.04179231, 0.04519223, 0.03743146,\n",
       "        0.03214187, 0.04019144, 0.03938761, 0.03103903, 0.03662765,\n",
       "        0.0381251 , 0.03926672, 0.03872234, 0.04286951, 0.03878696]),\n",
       " 'rank_test_score': array([19, 17, 18, 20,  4, 11, 10, 12, 16,  3,  7, 13,  8,  5,  1,  6, 14,\n",
       "        15,  9,  2])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7624f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7929827138062431"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2447b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20, min_samples_split=4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06f504dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9860879243183083"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2089317c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(digits.data)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883edca7",
   "metadata": {},
   "source": [
    "## Assignment - wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e65c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35d11415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a2dc2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3      4     5     6     7     8      9     10  \\\n",
       "0    14.23  1.71  2.43  15.6  127.0  2.80  3.06  0.28  2.29   5.64  1.04   \n",
       "1    13.20  1.78  2.14  11.2  100.0  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "2    13.16  2.36  2.67  18.6  101.0  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "3    14.37  1.95  2.50  16.8  113.0  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "4    13.24  2.59  2.87  21.0  118.0  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "..     ...   ...   ...   ...    ...   ...   ...   ...   ...    ...   ...   \n",
       "173  13.71  5.65  2.45  20.5   95.0  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "174  13.40  3.91  2.48  23.0  102.0  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "175  13.27  4.28  2.26  20.0  120.0  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "176  13.17  2.59  2.37  20.0  120.0  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "177  14.13  4.10  2.74  24.5   96.0  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "       11      12  \n",
       "0    3.92  1065.0  \n",
       "1    3.40  1050.0  \n",
       "2    3.17  1185.0  \n",
       "3    3.45  1480.0  \n",
       "4    2.93   735.0  \n",
       "..    ...     ...  \n",
       "173  1.74   740.0  \n",
       "174  1.56   750.0  \n",
       "175  1.56   835.0  \n",
       "176  1.62   840.0  \n",
       "177  1.60   560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.DataFrame(wine.data)\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1624a",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e71c275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# LOG\\ngrid_search_log = GridSearchCV(log_clf, param_grid={'max_iter':range(500,20000,500), 'solver':['newton-cg', 'lbfgs', 'saga']}, cv=5, n_jobs=-1,verbose=3)\\ngrid_search_log.fit(wine.data, wine.target)\\nlog_model = grid_search_log.best_estimator_\\nprint(log_model)\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# LOG\n",
    "grid_search_log = GridSearchCV(log_clf, param_grid={'max_iter':range(500,20000,500), 'solver':['newton-cg', 'lbfgs', 'saga']}, cv=5, n_jobs=-1,verbose=3)\n",
    "grid_search_log.fit(wine.data, wine.target)\n",
    "log_model = grid_search_log.best_estimator_\n",
    "print(log_model)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a2ececf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# RF\\ngrid_search_rf = GridSearchCV(rf, param_grid={'max_depth':range(5,30,5), 'min_samples_split':[2,3,4,5]}, cv=5, n_jobs=-1, verbose=3)\\ngrid_search_rf.fit(wine.data, wine.target)\\nrf_model = grid_search_rf.best_estimator_\\nprint(rf_model)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# RF\n",
    "grid_search_rf = GridSearchCV(rf, param_grid={'max_depth':range(5,30,5), 'min_samples_split':[2,3,4,5]}, cv=5, n_jobs=-1, verbose=3)\n",
    "grid_search_rf.fit(wine.data, wine.target)\n",
    "rf_model = grid_search_rf.best_estimator_\n",
    "print(rf_model)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4890d042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# SVC\\ngrid_search_svc = GridSearchCV(svc, param_grid={'C':range(1,50,1), 'kernel':['linear', 'poly', 'rbf', 'sigmoid']}, cv=5, n_jobs=-1,verbose=3)\\ngrid_search_svc.fit(wine.data, wine.target)\\nsvc_model = grid_search_svc.best_estimator_\\nprint(svc_model)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# SVC\n",
    "grid_search_svc = GridSearchCV(svc, param_grid={'C':range(1,50,1), 'kernel':['linear', 'poly', 'rbf', 'sigmoid']}, cv=5, n_jobs=-1,verbose=3)\n",
    "grid_search_svc.fit(wine.data, wine.target)\n",
    "svc_model = grid_search_svc.best_estimator_\n",
    "print(svc_model)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fb548da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# KNN\\ngrid_search_knn = GridSearchCV(knn, param_grid={'n_neighbors':range(2,15,1)}, cv=5, n_jobs=-1,verbose=3)\\ngrid_search_knn.fit(wine.data, wine.target)\\nknn_model = grid_search_knn.best_estimator_\\nprint(knn_model)\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# KNN\n",
    "grid_search_knn = GridSearchCV(knn, param_grid={'n_neighbors':range(2,15,1)}, cv=5, n_jobs=-1,verbose=3)\n",
    "grid_search_knn.fit(wine.data, wine.target)\n",
    "knn_model = grid_search_knn.best_estimator_\n",
    "print(knn_model)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89dae2",
   "metadata": {},
   "source": [
    "### Make Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0432355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def get_reports(y_test, y_pred):\n",
    "    print(\"\\nAccuracy:\",accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision Score:\",precision_score(y_test, y_pred, average = 'macro', zero_division=0))\n",
    "    print(\"Recall Score:\",recall_score(y_test, y_pred, average = 'macro', zero_division=0))\n",
    "    print(\"f1 Score:\",f1_score(y_test, y_pred, average = 'macro', zero_division=0))\n",
    "    \n",
    "    print(\"\\n \\nClassification Report:\\n\\n\",classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"\\n \\nConfusion Matrix:\\n\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15c393aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logclf = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90934d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4ea6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "model_list = [LogisticRegression(), RandomForestClassifier(), SVC(), KNeighborsClassifier()]\n",
    "\n",
    "for model in model_list:\n",
    "    pipeline= make_pipeline(SimpleImputer(strategy='median'), RobustScaler(), model, verbose=True) \n",
    "    pipelines.append(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1d3fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 117 candidates, totalling 585 fits\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing logisticregression, total=   0.0s\n",
      "\n",
      "\n",
      "Model: Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
      "                ('robustscaler', RobustScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(max_iter=500, solver='newton-cg'))],\n",
      "         verbose=True)\n",
      "\n",
      " Test score: 0.9722222222222222\n",
      "\n",
      " Train score: 1.0 \n",
      "\n",
      "\n",
      "Accuracy: 0.9722222222222222\n",
      "Precision Score: 0.9761904761904763\n",
      "Recall Score: 0.9696969696969697\n",
      "f1 Score: 0.9717813051146384\n",
      "\n",
      " \n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      " \n",
      "Confusion Matrix:\n",
      "\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 10]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cross Validate:\n",
      "\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing logisticregression, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing logisticregression, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing logisticregression, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing logisticregression, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing logisticregression, total=   0.0s\n",
      "\n",
      " ('logisticregression', LogisticRegression()) \n",
      "\n",
      "Mean Accuracy: 0.9888888888888889\n",
      "Mean Precision: 0.9878787878787879\n",
      "Mean Recall: 0.9904761904761905\n",
      "\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.1s\n",
      "\n",
      "\n",
      "Model: Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
      "                ('robustscaler', RobustScaler()),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=20))],\n",
      "         verbose=True)\n",
      "\n",
      " Test score: 1.0\n",
      "\n",
      " Train score: 1.0 \n",
      "\n",
      "\n",
      "Accuracy: 1.0\n",
      "Precision Score: 1.0\n",
      "Recall Score: 1.0\n",
      "f1 Score: 1.0\n",
      "\n",
      " \n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      " \n",
      "Confusion Matrix:\n",
      "\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cross Validate:\n",
      "\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.1s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.1s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.1s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.1s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.1s\n",
      "\n",
      " ('randomforestclassifier', RandomForestClassifier()) \n",
      "\n",
      "Mean Accuracy: 0.9777777777777779\n",
      "Mean Precision: 0.9783061383061383\n",
      "Mean Recall: 0.9801587301587302\n",
      "\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 196 candidates, totalling 980 fits\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing svc, total=   0.0s\n",
      "\n",
      "\n",
      "Model: Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
      "                ('robustscaler', RobustScaler()), ('svc', SVC(C=1))],\n",
      "         verbose=True)\n",
      "\n",
      " Test score: 0.9444444444444444\n",
      "\n",
      " Train score: 1.0 \n",
      "\n",
      "\n",
      "Accuracy: 0.9444444444444444\n",
      "Precision Score: 0.9555555555555556\n",
      "Recall Score: 0.9419191919191919\n",
      "f1 Score: 0.945824706694272\n",
      "\n",
      " \n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.95        36\n",
      "\n",
      "\n",
      " \n",
      "Confusion Matrix:\n",
      "\n",
      "[[11  1  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 10]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cross Validate:\n",
      "\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing svc, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing svc, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing svc, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing svc, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing svc, total=   0.0s\n",
      "\n",
      " ('svc', SVC()) \n",
      "\n",
      "Mean Accuracy: 0.9833333333333334\n",
      "Mean Precision: 0.9856060606060606\n",
      "Mean Recall: 0.9830158730158729\n",
      "\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing kneighborsclassifier, total=   0.0s\n",
      "\n",
      "\n",
      "Model: Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
      "                ('robustscaler', RobustScaler()),\n",
      "                ('kneighborsclassifier', KNeighborsClassifier(n_neighbors=12))],\n",
      "         verbose=True)\n",
      "\n",
      " Test score: 0.9722222222222222\n",
      "\n",
      " Train score: 0.9577464788732394 \n",
      "\n",
      "\n",
      "Accuracy: 0.9722222222222222\n",
      "Precision Score: 0.9761904761904763\n",
      "Recall Score: 0.9696969696969697\n",
      "f1 Score: 0.9717813051146384\n",
      "\n",
      " \n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      " \n",
      "Confusion Matrix:\n",
      "\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 10]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cross Validate:\n",
      "\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing kneighborsclassifier, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing kneighborsclassifier, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing kneighborsclassifier, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing kneighborsclassifier, total=   0.0s\n",
      "[Pipeline] ..... (step 1 of 3) Processing simpleimputer, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing robustscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing kneighborsclassifier, total=   0.0s\n",
      "\n",
      " ('kneighborsclassifier', KNeighborsClassifier()) \n",
      "\n",
      "Mean Accuracy: 0.9553968253968254\n",
      "Mean Precision: 0.9581474081474083\n",
      "Mean Recall: 0.9622222222222222\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_list = [{'logisticregression__max_iter':list(range(500,20000,500)), 'logisticregression__solver':['newton-cg', 'lbfgs', 'saga']},\n",
    "              {'randomforestclassifier__max_depth':[10,50,100,200,250], 'randomforestclassifier__max_depth':list(range(5,30,5)), 'randomforestclassifier__min_samples_split':[2,3,4,5]},\n",
    "              {'svc__C':list(range(1,50,1)), 'svc__kernel':['linear', 'poly', 'rbf', 'sigmoid']},\n",
    "              {'kneighborsclassifier__n_neighbors':list(range(2,15,1))}]\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', 'accuracy']\n",
    "\n",
    "for pipeline, x in zip(pipelines, param_list):\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, x, cv=5, n_jobs=-1,verbose=3)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    model = grid_search.best_estimator_\n",
    "    print(\"\\n\\nModel:\",model)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"\\n Test score:\",model.score(x_test, y_test))\n",
    "    print(\"\\n Train score:\",model.score(x_train, y_train),\"\\n\")\n",
    "    get_reports(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nCross Validate:\\n\")\n",
    "    cv = cross_validate(model, wine.data, wine.target, scoring=scoring, cv=5)\n",
    "    print(\"\\n\",pipeline.steps[2],\"\\n\")\n",
    "    print(\"Mean Accuracy:\",cv['test_accuracy'].mean())\n",
    "    print(\"Mean Precision:\",cv['test_precision_macro'].mean())\n",
    "    print(\"Mean Recall:\",cv['test_recall_macro'].mean())\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3520cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly Assignment \n",
    "\n",
    "# Red Wine.csv\n",
    "\n",
    "# EDA\n",
    "# Utilise Pipelines, CV and Grid Search to optimize and get best results for classification.\n",
    "# Try with all known Classification Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0e6d6",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "\n",
    "* Unlike grid search not all parameters are tried and tested.\n",
    "* Rther a fixed number of parameter settings is sampled from the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e02fd964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# randint is an iterator for generating numbers between range specified\n",
    "\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab4ff49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "Y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5358e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db6dcd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specift parameters and distributions to sample from\n",
    "\n",
    "param_dist = {\"max_depth\":randint(5,30),\n",
    "              \"max_features\":[0.4, 0.6, 0.75],\n",
    "              \"min_samples_split\":randint(2,11),\n",
    "              \"criterion\":[\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f28d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "caf53528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Randomized Search CV took 103.57 secs for 50 candidates parameter settings\n"
     ]
    }
   ],
   "source": [
    "n_iter = 50\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=n_iter, cv =5, n_jobs= -1, verbose=1)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X,Y)\n",
    "\n",
    "print(\"Randomized Search CV took %.2f secs for %d candidates parameter settings\" %((time()-start), n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2657705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933237387805633"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8313682b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 28,\n",
       " 'max_features': 0.4,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ef05d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Grid Search CV took 223.46 secs for 120 candidates parameter settings\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"max_depth\":[3,5,9,13,15],\n",
    "              \"max_features\":[0.4,0.5,0.75],\n",
    "              \"min_samples_split\":[2,3,5,7],\n",
    "              \"criterion\":[\"gini\", \"entropy\"]}\n",
    "\n",
    "# Run Grid Search\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid, cv =5, n_jobs= -1, verbose=1)\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "print(\"Grid Search CV took %.2f secs for %d candidates parameter settings\" %((time()-start), len(grid_search.cv_results_['params'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3c5297d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354596100278553"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35b61bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 9,\n",
       " 'max_features': 0.4,\n",
       " 'min_samples_split': 3}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "993b04d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=9, max_features=0.4,\n",
       "                       min_samples_split=3, n_estimators=200)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fac796",
   "metadata": {},
   "source": [
    "## Model Persistance\n",
    "\n",
    "* Model training is an expensive process\n",
    "* Thus is it desirable to save it as a file on Hard disk\n",
    "* Using pickle or joblib we could easily save the model as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5667177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b019af98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\DEVVRAK\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "136d90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = SVC()\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "robust_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abcc7c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                                       ('svc', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'svc__C': [1, 5, 10, 50, 100],\n",
       "                         'svc__degree': [3, 4, 5, 6, 7, 10],\n",
       "                         'svc__gamma': [0.1, 0.5, 1.5, 10],\n",
       "                         'svc__kernel': ['poly', 'rbf', 'linear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(robust_scaler, svc_clf)\n",
    "\n",
    "param_grid = {'svc__C': [1,5,10,50,100],\n",
    "              'svc__kernel':['poly', 'rbf', 'linear'],\n",
    "              'svc__degree':[3,4,5,6,7,10],\n",
    "              'svc__gamma':[0.1,0.5,1.5,10]}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv =5, n_jobs= -1, verbose=1)\n",
    "grid_search.fit(cancer_data.data, cancer_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "402b5287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                ('svc', SVC(C=1, gamma=0.1, kernel='linear'))])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f251cba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'linear'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90b69d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02396121, 0.03074007, 0.02319851, 0.02143512, 0.04119868,\n",
       "        0.01894813, 0.01730409, 0.04120803, 0.01613426, 0.02965536,\n",
       "        0.04451365, 0.01519756, 0.01944165, 0.02212505, 0.01600327,\n",
       "        0.02337232, 0.03447499, 0.01424413, 0.0205194 , 0.03845339,\n",
       "        0.01425533, 0.02059283, 0.04069524, 0.01344609, 0.01365833,\n",
       "        0.01783566, 0.01655893, 0.02163177, 0.04527459, 0.01835384,\n",
       "        0.01675839, 0.03796368, 0.01454825, 0.01997433, 0.05174479,\n",
       "        0.01522322, 0.02672477, 0.02395401, 0.01406412, 0.03237157,\n",
       "        0.04102745, 0.0158216 , 0.0260221 , 0.0366827 , 0.01296306,\n",
       "        0.02299037, 0.04410963, 0.01288724, 0.01491952, 0.02048764,\n",
       "        0.01324921, 0.0154438 , 0.03717213, 0.01335974, 0.02116899,\n",
       "        0.03771181, 0.01420484, 0.01741891, 0.04334211, 0.01330972,\n",
       "        0.0224895 , 0.01845789, 0.01358042, 0.03542504, 0.03331318,\n",
       "        0.01336465, 0.0331706 , 0.04096565, 0.01666036, 0.03116374,\n",
       "        0.04244533, 0.01558046, 0.0153676 , 0.01904631, 0.022544  ,\n",
       "        0.01641383, 0.03210135, 0.01445327, 0.01612473, 0.03244772,\n",
       "        0.01946211, 0.01676488, 0.04791107, 0.0145236 , 0.02335758,\n",
       "        0.02081013, 0.01639729, 0.02419066, 0.03429699, 0.01850739,\n",
       "        0.02297802, 0.04030194, 0.02155523, 0.03174424, 0.05706072,\n",
       "        0.0244895 , 0.01878386, 0.02470417, 0.02082067, 0.01706543,\n",
       "        0.04043379, 0.02186418, 0.01515131, 0.04177103, 0.02288871,\n",
       "        0.01502719, 0.04575868, 0.02011814, 0.02182412, 0.01866846,\n",
       "        0.01348333, 0.02537403, 0.03054252, 0.01670432, 0.02597847,\n",
       "        0.03716526, 0.01602306, 0.02851024, 0.04323611, 0.01517425,\n",
       "        0.01880121, 0.01925583, 0.0163909 , 0.01715798, 0.03717046,\n",
       "        0.01963615, 0.01972237, 0.03878837, 0.01878877, 0.01801028,\n",
       "        0.04648414, 0.0175159 , 0.02477336, 0.01982656, 0.01592607,\n",
       "        0.03207159, 0.03483701, 0.01600432, 0.03686895, 0.03828645,\n",
       "        0.01854711, 0.03096285, 0.04581852, 0.01829219, 0.01718731,\n",
       "        0.02069893, 0.0209312 , 0.01530762, 0.03390131, 0.01876063,\n",
       "        0.0189755 , 0.03626385, 0.02516694, 0.0194808 , 0.04466276,\n",
       "        0.01871738, 0.02078719, 0.0213191 , 0.01959281, 0.02339015,\n",
       "        0.0330337 , 0.01882887, 0.02598515, 0.03698072, 0.01962447,\n",
       "        0.02341261, 0.04359851, 0.0177609 , 0.01660275, 0.02042751,\n",
       "        0.01763339, 0.01575561, 0.03965878, 0.01687579, 0.01611772,\n",
       "        0.04101057, 0.02006679, 0.01540461, 0.04447918, 0.0211864 ,\n",
       "        0.02549357, 0.02430892, 0.01831617, 0.0282958 , 0.03536148,\n",
       "        0.01964741, 0.02772541, 0.03809023, 0.01790318, 0.03163481,\n",
       "        0.0455915 , 0.01905165, 0.01562338, 0.01906977, 0.0196218 ,\n",
       "        0.01913214, 0.03604212, 0.0199019 , 0.01706386, 0.03849154,\n",
       "        0.01824598, 0.01699762, 0.04212675, 0.01772079, 0.02776952,\n",
       "        0.02158141, 0.01746812, 0.04147778, 0.03643813, 0.01764717,\n",
       "        0.03165126, 0.03498087, 0.02154884, 0.03292117, 0.05198236,\n",
       "        0.01666002, 0.01576648, 0.01885734, 0.03341489, 0.01510315,\n",
       "        0.03874946, 0.02657313, 0.01464748, 0.03583617, 0.02927113,\n",
       "        0.015415  , 0.04556851, 0.02865667, 0.0217792 , 0.02803445,\n",
       "        0.03306403, 0.02109241, 0.03503709, 0.03478479, 0.02274127,\n",
       "        0.04172907, 0.04898291, 0.02828307, 0.05847688, 0.04970784,\n",
       "        0.01682701, 0.0267961 , 0.04719477, 0.01884065, 0.05616808,\n",
       "        0.0549212 , 0.0346168 , 0.06258712, 0.04906735, 0.02846065,\n",
       "        0.07976079, 0.04980917, 0.04628263, 0.03714724, 0.05243297,\n",
       "        0.04867821, 0.05674214, 0.05336304, 0.04404712, 0.05778093,\n",
       "        0.04694767, 0.05508523, 0.0745719 , 0.04987454, 0.02245097,\n",
       "        0.03043079, 0.05606751, 0.03778901, 0.05782142, 0.04994192,\n",
       "        0.03008671, 0.06431313, 0.05727777, 0.03022585, 0.07149506,\n",
       "        0.05002604, 0.05446587, 0.03394547, 0.05460286, 0.07157888,\n",
       "        0.06044989, 0.05446329, 0.06834092, 0.06774659, 0.05256753,\n",
       "        0.0514184 , 0.0809309 , 0.05385537, 0.02537384, 0.03428988,\n",
       "        0.05620375, 0.03034172, 0.05619912, 0.05355825, 0.03263779,\n",
       "        0.06713896, 0.06312733, 0.03009024, 0.06741891, 0.05454764,\n",
       "        0.03784194, 0.03734093, 0.05105677, 0.03944974, 0.06188302,\n",
       "        0.05050921, 0.03865919, 0.06631951, 0.05457497, 0.0434763 ,\n",
       "        0.074018  , 0.05664058, 0.02757087, 0.0334424 , 0.05310798,\n",
       "        0.02427325, 0.06186981, 0.06480198, 0.0268014 , 0.05824518,\n",
       "        0.06300502, 0.02937875, 0.09010878, 0.06588845, 0.04790463,\n",
       "        0.03863811, 0.05574131, 0.04014912, 0.05845227, 0.05831923,\n",
       "        0.04561582, 0.07570086, 0.05134578, 0.04210138, 0.07455392,\n",
       "        0.05082707, 0.03359785, 0.02854543, 0.06466413, 0.02615232,\n",
       "        0.05824165, 0.06031079, 0.02762861, 0.06149783, 0.05549707,\n",
       "        0.03137155, 0.08847575, 0.06214981, 0.05522342, 0.03396153,\n",
       "        0.0530674 , 0.05876632, 0.0609139 , 0.05259156, 0.06021466,\n",
       "        0.06639962, 0.05052519, 0.05280514, 0.07428594, 0.04547505]),\n",
       " 'std_fit_time': array([0.00324544, 0.00835453, 0.00345056, 0.00393297, 0.00675795,\n",
       "        0.00228898, 0.00220938, 0.01006601, 0.00238291, 0.01210315,\n",
       "        0.00550854, 0.00078415, 0.00196761, 0.00606523, 0.00444308,\n",
       "        0.00387895, 0.0023757 , 0.00185907, 0.0015835 , 0.01164373,\n",
       "        0.00064746, 0.00274131, 0.00423015, 0.00133436, 0.00048576,\n",
       "        0.00084542, 0.00433329, 0.0061167 , 0.0129558 , 0.0047022 ,\n",
       "        0.00189773, 0.00437049, 0.00188375, 0.01039664, 0.0064109 ,\n",
       "        0.004139  , 0.01049035, 0.01414151, 0.00123322, 0.01124267,\n",
       "        0.0105139 , 0.00263327, 0.00199311, 0.00578691, 0.00101734,\n",
       "        0.00150922, 0.00625207, 0.0006822 , 0.0021152 , 0.00213111,\n",
       "        0.00136156, 0.00305536, 0.00673316, 0.00088441, 0.00491271,\n",
       "        0.00851562, 0.00251352, 0.00487084, 0.00282031, 0.00155852,\n",
       "        0.00135962, 0.00234895, 0.00115937, 0.00353185, 0.00310552,\n",
       "        0.0015666 , 0.00444506, 0.00901564, 0.00615193, 0.00415156,\n",
       "        0.00588378, 0.00249631, 0.0025523 , 0.00256665, 0.0076326 ,\n",
       "        0.00292231, 0.0027044 , 0.00123668, 0.00245723, 0.00213937,\n",
       "        0.00726685, 0.00300522, 0.01055481, 0.00131653, 0.00459573,\n",
       "        0.00496128, 0.00078009, 0.00219801, 0.00604925, 0.00628363,\n",
       "        0.0020179 , 0.01201105, 0.01619229, 0.00802795, 0.01921764,\n",
       "        0.00843802, 0.00908892, 0.00982557, 0.00989707, 0.00387541,\n",
       "        0.01419144, 0.0055822 , 0.00198084, 0.01220477, 0.00518007,\n",
       "        0.00207683, 0.00946931, 0.00535049, 0.00278945, 0.003036  ,\n",
       "        0.00174462, 0.00172409, 0.00297664, 0.00294037, 0.00442202,\n",
       "        0.00340154, 0.00316618, 0.00607585, 0.0042445 , 0.00176425,\n",
       "        0.00833004, 0.00244587, 0.00346167, 0.00263432, 0.00301456,\n",
       "        0.00830765, 0.00460412, 0.00769582, 0.00345551, 0.00290789,\n",
       "        0.00539927, 0.00317193, 0.00242612, 0.00231167, 0.00215747,\n",
       "        0.00242057, 0.00548639, 0.00284964, 0.00388992, 0.00535285,\n",
       "        0.00378345, 0.00401706, 0.00690674, 0.00277944, 0.00411258,\n",
       "        0.00344162, 0.00595641, 0.00263684, 0.00202247, 0.00198989,\n",
       "        0.0036328 , 0.00287918, 0.00651383, 0.00489336, 0.00627132,\n",
       "        0.00361433, 0.00172049, 0.00548393, 0.00253458, 0.00231744,\n",
       "        0.00256803, 0.00369005, 0.00425085, 0.00557202, 0.003294  ,\n",
       "        0.00246964, 0.00329507, 0.00287121, 0.00207866, 0.00429404,\n",
       "        0.00213652, 0.00253506, 0.00540426, 0.00191489, 0.00298206,\n",
       "        0.00536133, 0.00500954, 0.00136177, 0.00481935, 0.00502253,\n",
       "        0.00503817, 0.01214094, 0.0036196 , 0.00463888, 0.00485768,\n",
       "        0.00383481, 0.00459896, 0.0030259 , 0.0024213 , 0.00980456,\n",
       "        0.00448099, 0.0042709 , 0.00249007, 0.00248779, 0.00452371,\n",
       "        0.00530767, 0.00177203, 0.00464511, 0.00268989, 0.00478834,\n",
       "        0.00154905, 0.00387274, 0.00503079, 0.00450901, 0.0035623 ,\n",
       "        0.00365633, 0.00165973, 0.01395144, 0.00455035, 0.00245012,\n",
       "        0.00442312, 0.00185271, 0.00426928, 0.00218647, 0.01114424,\n",
       "        0.00136826, 0.00249367, 0.00242014, 0.01106178, 0.00212035,\n",
       "        0.00576046, 0.00932741, 0.00115477, 0.0027582 , 0.01006   ,\n",
       "        0.00341258, 0.00661139, 0.00955259, 0.00115385, 0.01155303,\n",
       "        0.0142193 , 0.00161388, 0.00607566, 0.01274834, 0.00130009,\n",
       "        0.00463209, 0.00943856, 0.0048359 , 0.01702932, 0.01544827,\n",
       "        0.00106116, 0.01011502, 0.02707652, 0.00818312, 0.01202085,\n",
       "        0.01951147, 0.00943851, 0.01139467, 0.0200852 , 0.00550788,\n",
       "        0.0131151 , 0.01658945, 0.01414028, 0.00538636, 0.01939249,\n",
       "        0.00692339, 0.0058874 , 0.02045951, 0.01038345, 0.0086923 ,\n",
       "        0.01686026, 0.02208991, 0.00891036, 0.01680811, 0.00304357,\n",
       "        0.00258185, 0.01610496, 0.00751715, 0.00314395, 0.01739808,\n",
       "        0.00734734, 0.00640679, 0.01487819, 0.00097335, 0.00418672,\n",
       "        0.0189987 , 0.00721373, 0.00291146, 0.01964584, 0.01726598,\n",
       "        0.00404035, 0.01822614, 0.01789641, 0.00616446, 0.01788868,\n",
       "        0.00414231, 0.00657391, 0.01921907, 0.00358712, 0.00321102,\n",
       "        0.02137876, 0.00894929, 0.00758139, 0.01741766, 0.00399001,\n",
       "        0.01050066, 0.01842867, 0.00388397, 0.00647449, 0.01850006,\n",
       "        0.00747321, 0.00754684, 0.01274812, 0.00402987, 0.0075289 ,\n",
       "        0.01566358, 0.00321982, 0.01532885, 0.01877387, 0.00904322,\n",
       "        0.0087105 , 0.01732697, 0.00450515, 0.00330109, 0.01693647,\n",
       "        0.00386045, 0.00869208, 0.01658752, 0.00409392, 0.0029562 ,\n",
       "        0.02016826, 0.00385822, 0.01369749, 0.02020912, 0.00905314,\n",
       "        0.0069407 , 0.01337093, 0.00279498, 0.00270498, 0.01201812,\n",
       "        0.00504809, 0.01527772, 0.01668935, 0.00639534, 0.00750799,\n",
       "        0.01583784, 0.00877737, 0.00574352, 0.01812978, 0.00226763,\n",
       "        0.01166095, 0.0154922 , 0.00345161, 0.00651106, 0.0201249 ,\n",
       "        0.00469921, 0.01148076, 0.02600723, 0.00644608, 0.00373959,\n",
       "        0.01940715, 0.00774309, 0.00315662, 0.01848291, 0.0123482 ,\n",
       "        0.0045325 , 0.01581483, 0.00998739, 0.00463037, 0.01033174]),\n",
       " 'mean_score_time': array([0.00287867, 0.00786514, 0.00178471, 0.00204597, 0.01329165,\n",
       "        0.00096927, 0.00164671, 0.01667604, 0.00105019, 0.00139599,\n",
       "        0.01506495, 0.00098615, 0.00257926, 0.00582461, 0.0011126 ,\n",
       "        0.00179491, 0.01588621, 0.00099969, 0.00301104, 0.01899695,\n",
       "        0.00184364, 0.00153561, 0.01643839, 0.00092282, 0.00139532,\n",
       "        0.00610132, 0.0009973 , 0.00192766, 0.01229715, 0.00277839,\n",
       "        0.00155234, 0.01738129, 0.00118561, 0.00183854, 0.02176752,\n",
       "        0.00119653, 0.00258775, 0.02845516, 0.00255752, 0.00323539,\n",
       "        0.01741219, 0.00110159, 0.004354  , 0.01743503, 0.00131001,\n",
       "        0.00250602, 0.01598783, 0.0009973 , 0.00224657, 0.00735989,\n",
       "        0.00137267, 0.00149817, 0.01406517, 0.00124488, 0.0019145 ,\n",
       "        0.01421323, 0.00119615, 0.0016736 , 0.0158915 , 0.00119667,\n",
       "        0.00251036, 0.00558467, 0.00093002, 0.00234909, 0.01209626,\n",
       "        0.00111732, 0.00219173, 0.01419759, 0.00230675, 0.00256815,\n",
       "        0.0160109 , 0.00133305, 0.0013957 , 0.00542326, 0.00099764,\n",
       "        0.0017364 , 0.0133687 , 0.00093102, 0.00202069, 0.01408463,\n",
       "        0.00099721, 0.00208273, 0.01743283, 0.00099778, 0.00211525,\n",
       "        0.00798936, 0.00138707, 0.00185618, 0.01539235, 0.00102534,\n",
       "        0.0020422 , 0.0217875 , 0.0008657 , 0.00239344, 0.01908827,\n",
       "        0.00143104, 0.00212812, 0.00685596, 0.00251074, 0.00230527,\n",
       "        0.01730299, 0.0015419 , 0.00145292, 0.0184094 , 0.00183468,\n",
       "        0.00179505, 0.01591582, 0.00139637, 0.00196495, 0.00624037,\n",
       "        0.0009974 , 0.0022007 , 0.01211901, 0.00147777, 0.00492754,\n",
       "        0.0150279 , 0.00099735, 0.00213718, 0.01879573, 0.00115428,\n",
       "        0.0018404 , 0.00564384, 0.00155272, 0.00145092, 0.0142951 ,\n",
       "        0.00135484, 0.001436  , 0.01433949, 0.00131636, 0.00139637,\n",
       "        0.01660962, 0.00149751, 0.00248432, 0.00596824, 0.00106006,\n",
       "        0.00277858, 0.01306105, 0.00119796, 0.00239334, 0.01613946,\n",
       "        0.00095272, 0.0024426 , 0.01556826, 0.00099759, 0.0025455 ,\n",
       "        0.00566435, 0.00117764, 0.00159569, 0.01560926, 0.001406  ,\n",
       "        0.00222926, 0.01502233, 0.00113182, 0.00163217, 0.01622148,\n",
       "        0.00133319, 0.00213132, 0.00545073, 0.00112877, 0.00189934,\n",
       "        0.01496396, 0.00119772, 0.00203481, 0.02026267, 0.00179949,\n",
       "        0.00199456, 0.01512761, 0.0012291 , 0.00167155, 0.00558553,\n",
       "        0.00119796, 0.00140333, 0.01381912, 0.00180545, 0.00157394,\n",
       "        0.01559529, 0.00207405, 0.00180044, 0.01663423, 0.00173063,\n",
       "        0.00225883, 0.00632787, 0.00143437, 0.00239363, 0.01417446,\n",
       "        0.00099802, 0.00199418, 0.01665993, 0.00131888, 0.00263109,\n",
       "        0.01784225, 0.00209889, 0.00229793, 0.00538702, 0.00093741,\n",
       "        0.00292892, 0.01387897, 0.00103893, 0.00239334, 0.01591558,\n",
       "        0.00103951, 0.00159597, 0.01605201, 0.00103927, 0.00322142,\n",
       "        0.00746875, 0.00096402, 0.00259438, 0.0133636 , 0.00106049,\n",
       "        0.00221481, 0.01867137, 0.00187359, 0.00303073, 0.01671734,\n",
       "        0.00119557, 0.00145583, 0.00539761, 0.00099354, 0.00139694,\n",
       "        0.01472201, 0.00170197, 0.00127635, 0.01809859, 0.00119848,\n",
       "        0.00163383, 0.01716542, 0.00152302, 0.00199499, 0.00533099,\n",
       "        0.0011003 , 0.00186558, 0.01390276, 0.00113244, 0.00217533,\n",
       "        0.01975093, 0.00204592, 0.00240455, 0.02803516, 0.00195065,\n",
       "        0.00182443, 0.01138573, 0.00193272, 0.00159574, 0.02453713,\n",
       "        0.00179515, 0.00317383, 0.02636318, 0.00167847, 0.00300093,\n",
       "        0.02671618, 0.00219464, 0.00425925, 0.00970397, 0.00219502,\n",
       "        0.00366549, 0.02094054, 0.00209699, 0.00493903, 0.02437668,\n",
       "        0.00179658, 0.00410395, 0.02762833, 0.00155835, 0.00226965,\n",
       "        0.01047993, 0.0019485 , 0.00295219, 0.02379894, 0.00251822,\n",
       "        0.00272179, 0.02195144, 0.00242763, 0.00246611, 0.0269856 ,\n",
       "        0.00219607, 0.00433931, 0.00857449, 0.00199566, 0.00346255,\n",
       "        0.02159386, 0.0019856 , 0.00361214, 0.0240263 , 0.001717  ,\n",
       "        0.00420017, 0.02737088, 0.00210238, 0.00193467, 0.00777149,\n",
       "        0.00162487, 0.00188217, 0.02433691, 0.00184965, 0.00385551,\n",
       "        0.02453246, 0.00159535, 0.00190887, 0.02677293, 0.0015182 ,\n",
       "        0.00335803, 0.01568556, 0.0017972 , 0.00359817, 0.02356591,\n",
       "        0.00125537, 0.00349998, 0.03072705, 0.00161076, 0.00401826,\n",
       "        0.02835665, 0.00158057, 0.00305443, 0.00909209, 0.00143042,\n",
       "        0.00290661, 0.02165961, 0.00196815, 0.00265613, 0.02653203,\n",
       "        0.00565028, 0.0047976 , 0.02765718, 0.00144196, 0.00339646,\n",
       "        0.00998664, 0.00198102, 0.00371046, 0.02162809, 0.00207095,\n",
       "        0.00357094, 0.02767744, 0.00199537, 0.00419154, 0.02884965,\n",
       "        0.00129924, 0.00321131, 0.0078011 , 0.00183697, 0.00220709,\n",
       "        0.02543187, 0.00215144, 0.00246072, 0.02686753, 0.00144076,\n",
       "        0.00339541, 0.02861962, 0.00180483, 0.00490518, 0.01094508,\n",
       "        0.00208836, 0.00711551, 0.02240653, 0.00220251, 0.00458727,\n",
       "        0.02034321, 0.00144463, 0.00399537, 0.0241828 , 0.00453172]),\n",
       " 'std_score_time': array([6.66907167e-04, 1.45699199e-03, 4.20403761e-04, 6.39745914e-04,\n",
       "        6.01732095e-04, 1.96925583e-04, 4.82113882e-04, 2.03478690e-03,\n",
       "        1.27978989e-04, 4.88188537e-04, 8.50211203e-04, 1.27152310e-04,\n",
       "        1.03377580e-03, 7.60924590e-04, 4.69984516e-04, 7.46378607e-04,\n",
       "        6.62673365e-03, 2.26183724e-06, 1.98516688e-03, 7.22675686e-03,\n",
       "        1.13355345e-03, 4.09299624e-04, 2.54129234e-03, 9.13420876e-05,\n",
       "        3.51230709e-04, 7.43303092e-04, 3.37174788e-07, 6.11224563e-04,\n",
       "        1.09695163e-03, 2.78594640e-03, 5.78344917e-04, 5.75732334e-03,\n",
       "        2.78157568e-04, 6.68437645e-04, 5.66593831e-03, 3.98921995e-04,\n",
       "        6.29093856e-04, 4.11212317e-02, 2.72915099e-03, 2.08745725e-03,\n",
       "        4.13471666e-03, 1.26401571e-04, 4.75813044e-03, 4.29508840e-03,\n",
       "        5.75063015e-04, 8.81662634e-04, 1.79856699e-03, 3.98950589e-07,\n",
       "        3.85830670e-04, 2.87352705e-03, 7.48351016e-04, 4.45295636e-04,\n",
       "        2.56523213e-03, 4.96115518e-04, 5.08001393e-04, 8.41830535e-04,\n",
       "        7.45462605e-04, 8.50560339e-04, 2.16749368e-03, 3.98969778e-04,\n",
       "        3.96037601e-04, 4.88383019e-04, 1.34326593e-04, 5.31695485e-04,\n",
       "        6.44589038e-04, 2.40755199e-04, 2.47021457e-04, 1.46468935e-03,\n",
       "        1.79632415e-03, 5.20796877e-04, 1.47827139e-03, 6.49591279e-04,\n",
       "        4.88324624e-04, 4.63278340e-04, 8.20381667e-07, 3.10687458e-04,\n",
       "        3.58408895e-03, 8.47453800e-05, 1.18109663e-03, 1.06536334e-03,\n",
       "        4.42200589e-07, 1.09841888e-03, 4.61434700e-03, 7.53945746e-07,\n",
       "        2.40684754e-04, 3.80320853e-03, 5.58162354e-04, 1.91235160e-04,\n",
       "        6.27171291e-03, 1.33039327e-04, 6.37913146e-04, 1.65989050e-02,\n",
       "        2.27391487e-04, 7.97295633e-04, 3.18975442e-03, 5.33813553e-04,\n",
       "        6.78920505e-04, 1.80078702e-03, 2.07686287e-03, 8.66085724e-04,\n",
       "        5.22604664e-03, 4.56086464e-04, 3.82104197e-04, 3.46101785e-03,\n",
       "        1.18395730e-03, 3.98755369e-04, 1.13238452e-03, 4.88071550e-04,\n",
       "        3.63613269e-05, 1.60688460e-03, 1.90734863e-07, 7.35853854e-04,\n",
       "        9.34313022e-04, 7.74324135e-04, 5.12501267e-03, 2.59630755e-03,\n",
       "        1.05982355e-06, 7.70058557e-04, 6.38515459e-03, 4.28003907e-04,\n",
       "        1.89400920e-04, 5.84489475e-04, 7.47695346e-04, 3.48448426e-04,\n",
       "        1.44041244e-03, 8.56895792e-04, 6.01314931e-04, 7.54368854e-04,\n",
       "        6.35482214e-04, 4.88460925e-04, 1.48499248e-03, 4.15113436e-04,\n",
       "        4.46618980e-04, 1.08742458e-03, 1.25265711e-04, 1.02440665e-03,\n",
       "        1.46325954e-03, 4.01187010e-04, 4.89317472e-04, 3.08779439e-03,\n",
       "        9.12041286e-05, 5.54257512e-04, 1.28275652e-03, 8.71451706e-07,\n",
       "        1.73010978e-03, 1.26960717e-03, 4.10191127e-04, 4.88577819e-04,\n",
       "        4.73306326e-03, 3.36489539e-04, 4.96071904e-04, 2.08670529e-03,\n",
       "        2.65343465e-04, 5.23036969e-04, 1.02093558e-03, 4.24078509e-04,\n",
       "        4.47194518e-04, 4.50549727e-04, 2.54078446e-04, 4.94239371e-04,\n",
       "        5.50597536e-03, 3.98329099e-04, 8.03961590e-05, 8.06622376e-03,\n",
       "        7.53481529e-04, 3.50402318e-07, 8.96749301e-04, 4.04411984e-04,\n",
       "        4.13604906e-04, 7.98332878e-04, 4.00233535e-04, 4.97303986e-04,\n",
       "        1.92778064e-03, 1.18159612e-03, 4.61242308e-04, 2.47842148e-03,\n",
       "        5.12855231e-04, 7.54764081e-04, 3.06069626e-03, 7.39897793e-04,\n",
       "        3.87603278e-04, 3.34605291e-03, 4.09848913e-04, 4.88694596e-04,\n",
       "        1.71461028e-03, 9.29526743e-07, 4.62310777e-07, 2.80753389e-03,\n",
       "        6.42323925e-04, 7.77284039e-04, 3.22217032e-03, 1.01494958e-03,\n",
       "        1.24921411e-03, 4.89535885e-04, 1.20617031e-04, 2.55009221e-03,\n",
       "        2.75145659e-03, 8.26605982e-05, 1.95408180e-03, 2.29893366e-03,\n",
       "        6.44431033e-04, 4.88421976e-04, 2.48206117e-03, 8.25070220e-05,\n",
       "        9.74267639e-04, 3.09636643e-03, 6.70438132e-05, 4.85630603e-04,\n",
       "        9.70917094e-04, 1.24931972e-04, 4.41122274e-04, 5.71040717e-03,\n",
       "        1.50803551e-03, 1.16897492e-03, 3.20854678e-03, 3.99693160e-04,\n",
       "        3.97375598e-04, 7.33812299e-04, 3.26716628e-05, 4.87704197e-04,\n",
       "        1.82702506e-03, 8.75103806e-04, 3.92825403e-04, 5.00048776e-03,\n",
       "        4.00924995e-04, 6.04404019e-04, 2.66179026e-03, 3.35275766e-04,\n",
       "        6.30675713e-04, 6.44539349e-04, 2.03970014e-04, 2.59137214e-04,\n",
       "        1.89462504e-03, 2.69556910e-04, 4.12106855e-04, 8.65627135e-03,\n",
       "        6.38647881e-04, 7.95497437e-04, 1.16306954e-02, 6.36245905e-04,\n",
       "        4.89776606e-04, 5.67502915e-03, 8.89327399e-04, 7.98106327e-04,\n",
       "        2.20653315e-03, 7.45996298e-04, 8.73635232e-04, 3.60320596e-03,\n",
       "        5.76135939e-04, 5.45533228e-04, 3.23649406e-03, 7.45652572e-04,\n",
       "        1.47196645e-03, 2.54548691e-03, 3.98564463e-04, 4.16235397e-04,\n",
       "        2.10438511e-03, 1.28284223e-03, 3.65133507e-03, 1.31481794e-03,\n",
       "        3.98565120e-04, 5.03249211e-04, 5.05042787e-03, 5.37766905e-04,\n",
       "        6.06271822e-04, 1.81781422e-03, 7.10186040e-04, 6.35509892e-04,\n",
       "        5.96259992e-03, 2.26505120e-03, 1.23611993e-03, 3.16316874e-03,\n",
       "        1.33556940e-03, 8.02844248e-04, 4.76136847e-03, 9.80153840e-04,\n",
       "        8.07443210e-04, 2.83968093e-03, 6.31656999e-04, 1.00720521e-03,\n",
       "        5.96749222e-03, 1.09371300e-03, 1.01386904e-03, 2.32880227e-03,\n",
       "        5.13885872e-04, 1.38394118e-03, 2.36923870e-03, 1.07488275e-03,\n",
       "        6.42034746e-04, 1.01976771e-03, 6.39418794e-04, 7.08738142e-04,\n",
       "        3.22803540e-03, 1.29243543e-04, 2.76198618e-03, 2.88648574e-03,\n",
       "        6.29934654e-04, 7.82135375e-04, 3.30319156e-03, 4.40942678e-04,\n",
       "        4.00244073e-04, 4.06459158e-03, 3.99830161e-04, 1.98670996e-03,\n",
       "        4.37619582e-03, 4.22853202e-04, 4.23380407e-04, 7.21969728e-03,\n",
       "        5.44595716e-04, 1.26851084e-03, 1.89488464e-03, 5.04955435e-04,\n",
       "        9.74085888e-04, 2.70737440e-03, 4.89769067e-04, 1.02830517e-03,\n",
       "        3.53741202e-03, 7.22075297e-04, 7.54404648e-04, 3.89813019e-03,\n",
       "        8.29537206e-03, 3.32409566e-03, 2.21923430e-03, 4.24843872e-04,\n",
       "        1.05486532e-03, 1.81955959e-03, 1.10584149e-03, 7.75634795e-04,\n",
       "        4.54861873e-03, 1.54248264e-04, 5.60279838e-04, 1.00522762e-02,\n",
       "        6.31585305e-04, 1.16231546e-03, 5.18513835e-03, 4.02067062e-04,\n",
       "        1.45891996e-03, 1.45823221e-03, 5.77521465e-04, 7.42747392e-04,\n",
       "        3.48551755e-03, 3.11519960e-04, 5.28051458e-04, 2.81319844e-03,\n",
       "        3.92069650e-04, 2.05317867e-03, 5.79815288e-03, 4.03982452e-04,\n",
       "        5.75434675e-04, 2.24662553e-03, 4.67512666e-04, 4.03311736e-03,\n",
       "        2.09121920e-03, 6.90532682e-04, 7.98154139e-04, 1.85043367e-03,\n",
       "        7.85001423e-04, 9.87647074e-04, 1.01731205e-03, 5.23942238e-03]),\n",
       " 'param_svc__C': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svc__degree': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svc__gamma': masked_array(data=[0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10,\n",
       "                    10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10,\n",
       "                    10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5,\n",
       "                    10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5,\n",
       "                    1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5,\n",
       "                    1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5,\n",
       "                    1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5,\n",
       "                    0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5,\n",
       "                    0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1,\n",
       "                    0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1,\n",
       "                    0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1,\n",
       "                    0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10,\n",
       "                    0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10,\n",
       "                    10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10,\n",
       "                    10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5,\n",
       "                    10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5,\n",
       "                    1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5,\n",
       "                    1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5,\n",
       "                    1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5,\n",
       "                    0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5,\n",
       "                    0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1,\n",
       "                    0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1,\n",
       "                    0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1,\n",
       "                    0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10,\n",
       "                    0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10, 10,\n",
       "                    10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 10,\n",
       "                    10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5, 1.5,\n",
       "                    10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5, 1.5,\n",
       "                    1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.5,\n",
       "                    1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5,\n",
       "                    1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5, 0.5,\n",
       "                    0.5, 1.5, 1.5, 1.5, 10, 10, 10, 0.1, 0.1, 0.1, 0.5,\n",
       "                    0.5, 0.5, 1.5, 1.5, 1.5, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svc__kernel': masked_array(data=['poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear',\n",
       "                    'poly', 'rbf', 'linear', 'poly', 'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'svc__C': 1,\n",
       "   'svc__degree': 3,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 1, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 5, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 0.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 1.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 10, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 0.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 1.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 50, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 3,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 3,\n",
       "   'svc__gamma': 0.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 3,\n",
       "   'svc__gamma': 1.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100, 'svc__degree': 3, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 4,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 4,\n",
       "   'svc__gamma': 0.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 4,\n",
       "   'svc__gamma': 1.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100, 'svc__degree': 4, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 5,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 5,\n",
       "   'svc__gamma': 0.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 5,\n",
       "   'svc__gamma': 1.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100, 'svc__degree': 5, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 6,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 6,\n",
       "   'svc__gamma': 0.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 6,\n",
       "   'svc__gamma': 1.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100, 'svc__degree': 6, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 7,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 7,\n",
       "   'svc__gamma': 0.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 7,\n",
       "   'svc__gamma': 1.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100, 'svc__degree': 7, 'svc__gamma': 10, 'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 0.1,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 10, 'svc__gamma': 0.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 0.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 10, 'svc__gamma': 1.5, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 1.5,\n",
       "   'svc__kernel': 'linear'},\n",
       "  {'svc__C': 100, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'poly'},\n",
       "  {'svc__C': 100, 'svc__degree': 10, 'svc__gamma': 10, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 100,\n",
       "   'svc__degree': 10,\n",
       "   'svc__gamma': 10,\n",
       "   'svc__kernel': 'linear'}],\n",
       " 'split0_test_score': array([0.94736842, 0.96491228, 0.97368421, 0.93859649, 0.87719298,\n",
       "        0.97368421, 0.93859649, 0.63157895, 0.97368421, 0.93859649,\n",
       "        0.62280702, 0.97368421, 0.90350877, 0.96491228, 0.97368421,\n",
       "        0.85087719, 0.87719298, 0.97368421, 0.85087719, 0.63157895,\n",
       "        0.97368421, 0.85087719, 0.62280702, 0.97368421, 0.9122807 ,\n",
       "        0.96491228, 0.97368421, 0.9122807 , 0.87719298, 0.97368421,\n",
       "        0.9122807 , 0.63157895, 0.97368421, 0.9122807 , 0.62280702,\n",
       "        0.97368421, 0.88596491, 0.96491228, 0.97368421, 0.85087719,\n",
       "        0.87719298, 0.97368421, 0.85087719, 0.63157895, 0.97368421,\n",
       "        0.85087719, 0.62280702, 0.97368421, 0.9122807 , 0.96491228,\n",
       "        0.97368421, 0.92982456, 0.87719298, 0.97368421, 0.92982456,\n",
       "        0.63157895, 0.97368421, 0.92982456, 0.62280702, 0.97368421,\n",
       "        0.85964912, 0.96491228, 0.97368421, 0.81578947, 0.87719298,\n",
       "        0.97368421, 0.81578947, 0.63157895, 0.97368421, 0.81578947,\n",
       "        0.62280702, 0.97368421, 0.98245614, 0.94736842, 0.95614035,\n",
       "        0.93859649, 0.86842105, 0.95614035, 0.93859649, 0.63157895,\n",
       "        0.95614035, 0.93859649, 0.62280702, 0.95614035, 0.9122807 ,\n",
       "        0.94736842, 0.95614035, 0.85087719, 0.86842105, 0.95614035,\n",
       "        0.85087719, 0.63157895, 0.95614035, 0.85087719, 0.62280702,\n",
       "        0.95614035, 0.94736842, 0.94736842, 0.95614035, 0.9122807 ,\n",
       "        0.86842105, 0.95614035, 0.9122807 , 0.63157895, 0.95614035,\n",
       "        0.9122807 , 0.62280702, 0.95614035, 0.86842105, 0.94736842,\n",
       "        0.95614035, 0.85087719, 0.86842105, 0.95614035, 0.85087719,\n",
       "        0.63157895, 0.95614035, 0.85087719, 0.62280702, 0.95614035,\n",
       "        0.92982456, 0.94736842, 0.95614035, 0.92982456, 0.86842105,\n",
       "        0.95614035, 0.92982456, 0.63157895, 0.95614035, 0.92982456,\n",
       "        0.62280702, 0.95614035, 0.83333333, 0.94736842, 0.95614035,\n",
       "        0.81578947, 0.86842105, 0.95614035, 0.81578947, 0.63157895,\n",
       "        0.95614035, 0.81578947, 0.62280702, 0.95614035, 0.98245614,\n",
       "        0.93859649, 0.95614035, 0.93859649, 0.86842105, 0.95614035,\n",
       "        0.93859649, 0.63157895, 0.95614035, 0.93859649, 0.62280702,\n",
       "        0.95614035, 0.90350877, 0.93859649, 0.95614035, 0.85087719,\n",
       "        0.86842105, 0.95614035, 0.85087719, 0.63157895, 0.95614035,\n",
       "        0.85087719, 0.62280702, 0.95614035, 0.95614035, 0.93859649,\n",
       "        0.95614035, 0.9122807 , 0.86842105, 0.95614035, 0.9122807 ,\n",
       "        0.63157895, 0.95614035, 0.9122807 , 0.62280702, 0.95614035,\n",
       "        0.85087719, 0.93859649, 0.95614035, 0.85087719, 0.86842105,\n",
       "        0.95614035, 0.85087719, 0.63157895, 0.95614035, 0.85087719,\n",
       "        0.62280702, 0.95614035, 0.93859649, 0.93859649, 0.95614035,\n",
       "        0.92982456, 0.86842105, 0.95614035, 0.92982456, 0.63157895,\n",
       "        0.95614035, 0.92982456, 0.62280702, 0.95614035, 0.83333333,\n",
       "        0.93859649, 0.95614035, 0.81578947, 0.86842105, 0.95614035,\n",
       "        0.81578947, 0.63157895, 0.95614035, 0.81578947, 0.62280702,\n",
       "        0.95614035, 0.94736842, 0.92105263, 0.95614035, 0.93859649,\n",
       "        0.86842105, 0.95614035, 0.93859649, 0.63157895, 0.95614035,\n",
       "        0.93859649, 0.62280702, 0.95614035, 0.88596491, 0.92105263,\n",
       "        0.95614035, 0.85087719, 0.86842105, 0.95614035, 0.85087719,\n",
       "        0.63157895, 0.95614035, 0.85087719, 0.62280702, 0.95614035,\n",
       "        0.95614035, 0.92105263, 0.95614035, 0.9122807 , 0.86842105,\n",
       "        0.95614035, 0.9122807 , 0.63157895, 0.95614035, 0.9122807 ,\n",
       "        0.62280702, 0.95614035, 0.85964912, 0.92105263, 0.95614035,\n",
       "        0.85087719, 0.86842105, 0.95614035, 0.85087719, 0.63157895,\n",
       "        0.95614035, 0.85087719, 0.62280702, 0.95614035, 0.93859649,\n",
       "        0.92105263, 0.95614035, 0.92982456, 0.86842105, 0.95614035,\n",
       "        0.92982456, 0.63157895, 0.95614035, 0.92982456, 0.62280702,\n",
       "        0.95614035, 0.84210526, 0.92105263, 0.95614035, 0.81578947,\n",
       "        0.86842105, 0.95614035, 0.81578947, 0.63157895, 0.95614035,\n",
       "        0.81578947, 0.62280702, 0.95614035, 0.93859649, 0.92105263,\n",
       "        0.94736842, 0.93859649, 0.86842105, 0.94736842, 0.93859649,\n",
       "        0.63157895, 0.94736842, 0.93859649, 0.62280702, 0.94736842,\n",
       "        0.85964912, 0.92105263, 0.94736842, 0.85087719, 0.86842105,\n",
       "        0.94736842, 0.85087719, 0.63157895, 0.94736842, 0.85087719,\n",
       "        0.62280702, 0.94736842, 0.94736842, 0.92105263, 0.94736842,\n",
       "        0.9122807 , 0.86842105, 0.94736842, 0.9122807 , 0.63157895,\n",
       "        0.94736842, 0.9122807 , 0.62280702, 0.94736842, 0.87719298,\n",
       "        0.92105263, 0.94736842, 0.85087719, 0.86842105, 0.94736842,\n",
       "        0.85087719, 0.63157895, 0.94736842, 0.85087719, 0.62280702,\n",
       "        0.94736842, 0.93859649, 0.92105263, 0.94736842, 0.92982456,\n",
       "        0.86842105, 0.94736842, 0.92982456, 0.63157895, 0.94736842,\n",
       "        0.92982456, 0.62280702, 0.94736842, 0.84210526, 0.92105263,\n",
       "        0.94736842, 0.81578947, 0.86842105, 0.94736842, 0.81578947,\n",
       "        0.63157895, 0.94736842, 0.81578947, 0.62280702, 0.94736842]),\n",
       " 'split1_test_score': array([0.92982456, 0.95614035, 0.97368421, 0.94736842, 0.92105263,\n",
       "        0.97368421, 0.94736842, 0.62280702, 0.97368421, 0.94736842,\n",
       "        0.62280702, 0.97368421, 0.88596491, 0.95614035, 0.97368421,\n",
       "        0.88596491, 0.92105263, 0.97368421, 0.88596491, 0.62280702,\n",
       "        0.97368421, 0.88596491, 0.62280702, 0.97368421, 0.9122807 ,\n",
       "        0.95614035, 0.97368421, 0.92982456, 0.92105263, 0.97368421,\n",
       "        0.92982456, 0.62280702, 0.97368421, 0.92982456, 0.62280702,\n",
       "        0.97368421, 0.87719298, 0.95614035, 0.97368421, 0.8245614 ,\n",
       "        0.92105263, 0.97368421, 0.8245614 , 0.62280702, 0.97368421,\n",
       "        0.8245614 , 0.62280702, 0.97368421, 0.89473684, 0.95614035,\n",
       "        0.97368421, 0.9122807 , 0.92105263, 0.97368421, 0.9122807 ,\n",
       "        0.62280702, 0.97368421, 0.9122807 , 0.62280702, 0.97368421,\n",
       "        0.84210526, 0.95614035, 0.97368421, 0.79824561, 0.92105263,\n",
       "        0.97368421, 0.79824561, 0.62280702, 0.97368421, 0.79824561,\n",
       "        0.62280702, 0.97368421, 0.94736842, 0.94736842, 0.95614035,\n",
       "        0.94736842, 0.92105263, 0.95614035, 0.94736842, 0.62280702,\n",
       "        0.95614035, 0.94736842, 0.62280702, 0.95614035, 0.89473684,\n",
       "        0.94736842, 0.95614035, 0.88596491, 0.92105263, 0.95614035,\n",
       "        0.88596491, 0.62280702, 0.95614035, 0.88596491, 0.62280702,\n",
       "        0.95614035, 0.89473684, 0.94736842, 0.95614035, 0.92982456,\n",
       "        0.92105263, 0.95614035, 0.92982456, 0.62280702, 0.95614035,\n",
       "        0.92982456, 0.62280702, 0.95614035, 0.88596491, 0.94736842,\n",
       "        0.95614035, 0.8245614 , 0.92105263, 0.95614035, 0.8245614 ,\n",
       "        0.62280702, 0.95614035, 0.8245614 , 0.62280702, 0.95614035,\n",
       "        0.88596491, 0.94736842, 0.95614035, 0.9122807 , 0.92105263,\n",
       "        0.95614035, 0.9122807 , 0.62280702, 0.95614035, 0.9122807 ,\n",
       "        0.62280702, 0.95614035, 0.8245614 , 0.94736842, 0.95614035,\n",
       "        0.79824561, 0.92105263, 0.95614035, 0.79824561, 0.62280702,\n",
       "        0.95614035, 0.79824561, 0.62280702, 0.95614035, 0.95614035,\n",
       "        0.94736842, 0.95614035, 0.94736842, 0.92105263, 0.95614035,\n",
       "        0.94736842, 0.62280702, 0.95614035, 0.94736842, 0.62280702,\n",
       "        0.95614035, 0.90350877, 0.94736842, 0.95614035, 0.88596491,\n",
       "        0.92105263, 0.95614035, 0.88596491, 0.62280702, 0.95614035,\n",
       "        0.88596491, 0.62280702, 0.95614035, 0.88596491, 0.94736842,\n",
       "        0.95614035, 0.92982456, 0.92105263, 0.95614035, 0.92982456,\n",
       "        0.62280702, 0.95614035, 0.92982456, 0.62280702, 0.95614035,\n",
       "        0.87719298, 0.94736842, 0.95614035, 0.8245614 , 0.92105263,\n",
       "        0.95614035, 0.8245614 , 0.62280702, 0.95614035, 0.8245614 ,\n",
       "        0.62280702, 0.95614035, 0.89473684, 0.94736842, 0.95614035,\n",
       "        0.9122807 , 0.92105263, 0.95614035, 0.9122807 , 0.62280702,\n",
       "        0.95614035, 0.9122807 , 0.62280702, 0.95614035, 0.84210526,\n",
       "        0.94736842, 0.95614035, 0.79824561, 0.92105263, 0.95614035,\n",
       "        0.79824561, 0.62280702, 0.95614035, 0.79824561, 0.62280702,\n",
       "        0.95614035, 0.94736842, 0.94736842, 0.93859649, 0.94736842,\n",
       "        0.92105263, 0.93859649, 0.94736842, 0.62280702, 0.93859649,\n",
       "        0.94736842, 0.62280702, 0.93859649, 0.87719298, 0.94736842,\n",
       "        0.93859649, 0.88596491, 0.92105263, 0.93859649, 0.88596491,\n",
       "        0.62280702, 0.93859649, 0.88596491, 0.62280702, 0.93859649,\n",
       "        0.9122807 , 0.94736842, 0.93859649, 0.92982456, 0.92105263,\n",
       "        0.93859649, 0.92982456, 0.62280702, 0.93859649, 0.92982456,\n",
       "        0.62280702, 0.93859649, 0.83333333, 0.94736842, 0.93859649,\n",
       "        0.8245614 , 0.92105263, 0.93859649, 0.8245614 , 0.62280702,\n",
       "        0.93859649, 0.8245614 , 0.62280702, 0.93859649, 0.86842105,\n",
       "        0.94736842, 0.93859649, 0.9122807 , 0.92105263, 0.93859649,\n",
       "        0.9122807 , 0.62280702, 0.93859649, 0.9122807 , 0.62280702,\n",
       "        0.93859649, 0.78070175, 0.94736842, 0.93859649, 0.79824561,\n",
       "        0.92105263, 0.93859649, 0.79824561, 0.62280702, 0.93859649,\n",
       "        0.79824561, 0.62280702, 0.93859649, 0.94736842, 0.94736842,\n",
       "        0.92982456, 0.94736842, 0.92105263, 0.92982456, 0.94736842,\n",
       "        0.62280702, 0.92982456, 0.94736842, 0.62280702, 0.92982456,\n",
       "        0.88596491, 0.94736842, 0.92982456, 0.88596491, 0.92105263,\n",
       "        0.92982456, 0.88596491, 0.62280702, 0.92982456, 0.88596491,\n",
       "        0.62280702, 0.92982456, 0.92105263, 0.94736842, 0.92982456,\n",
       "        0.92982456, 0.92105263, 0.92982456, 0.92982456, 0.62280702,\n",
       "        0.92982456, 0.92982456, 0.62280702, 0.92982456, 0.84210526,\n",
       "        0.94736842, 0.92982456, 0.8245614 , 0.92105263, 0.92982456,\n",
       "        0.8245614 , 0.62280702, 0.92982456, 0.8245614 , 0.62280702,\n",
       "        0.92982456, 0.86842105, 0.94736842, 0.92982456, 0.9122807 ,\n",
       "        0.92105263, 0.92982456, 0.9122807 , 0.62280702, 0.92982456,\n",
       "        0.9122807 , 0.62280702, 0.92982456, 0.76315789, 0.94736842,\n",
       "        0.92982456, 0.79824561, 0.92105263, 0.92982456, 0.79824561,\n",
       "        0.62280702, 0.92982456, 0.79824561, 0.62280702, 0.92982456]),\n",
       " 'split2_test_score': array([0.96491228, 0.95614035, 0.97368421, 0.99122807, 0.92105263,\n",
       "        0.97368421, 0.99122807, 0.63157895, 0.97368421, 0.99122807,\n",
       "        0.63157895, 0.97368421, 0.89473684, 0.95614035, 0.97368421,\n",
       "        0.88596491, 0.92105263, 0.97368421, 0.88596491, 0.63157895,\n",
       "        0.97368421, 0.88596491, 0.63157895, 0.97368421, 0.94736842,\n",
       "        0.95614035, 0.97368421, 0.98245614, 0.92105263, 0.97368421,\n",
       "        0.98245614, 0.63157895, 0.97368421, 0.98245614, 0.63157895,\n",
       "        0.97368421, 0.86842105, 0.95614035, 0.97368421, 0.84210526,\n",
       "        0.92105263, 0.97368421, 0.84210526, 0.63157895, 0.97368421,\n",
       "        0.84210526, 0.63157895, 0.97368421, 0.92105263, 0.95614035,\n",
       "        0.97368421, 0.97368421, 0.92105263, 0.97368421, 0.97368421,\n",
       "        0.63157895, 0.97368421, 0.97368421, 0.63157895, 0.97368421,\n",
       "        0.84210526, 0.95614035, 0.97368421, 0.76315789, 0.92105263,\n",
       "        0.97368421, 0.76315789, 0.63157895, 0.97368421, 0.76315789,\n",
       "        0.63157895, 0.97368421, 0.98245614, 0.96491228, 0.96491228,\n",
       "        0.99122807, 0.93859649, 0.96491228, 0.99122807, 0.63157895,\n",
       "        0.96491228, 0.99122807, 0.63157895, 0.96491228, 0.89473684,\n",
       "        0.96491228, 0.96491228, 0.88596491, 0.93859649, 0.96491228,\n",
       "        0.88596491, 0.63157895, 0.96491228, 0.88596491, 0.63157895,\n",
       "        0.96491228, 0.97368421, 0.96491228, 0.96491228, 0.98245614,\n",
       "        0.93859649, 0.96491228, 0.98245614, 0.63157895, 0.96491228,\n",
       "        0.98245614, 0.63157895, 0.96491228, 0.85087719, 0.96491228,\n",
       "        0.96491228, 0.84210526, 0.93859649, 0.96491228, 0.84210526,\n",
       "        0.63157895, 0.96491228, 0.84210526, 0.63157895, 0.96491228,\n",
       "        0.95614035, 0.96491228, 0.96491228, 0.97368421, 0.93859649,\n",
       "        0.96491228, 0.97368421, 0.63157895, 0.96491228, 0.97368421,\n",
       "        0.63157895, 0.96491228, 0.8245614 , 0.96491228, 0.96491228,\n",
       "        0.76315789, 0.93859649, 0.96491228, 0.76315789, 0.63157895,\n",
       "        0.96491228, 0.76315789, 0.63157895, 0.96491228, 0.98245614,\n",
       "        0.95614035, 0.97368421, 0.99122807, 0.93859649, 0.97368421,\n",
       "        0.99122807, 0.63157895, 0.97368421, 0.99122807, 0.63157895,\n",
       "        0.97368421, 0.87719298, 0.95614035, 0.97368421, 0.88596491,\n",
       "        0.93859649, 0.97368421, 0.88596491, 0.63157895, 0.97368421,\n",
       "        0.88596491, 0.63157895, 0.97368421, 0.98245614, 0.95614035,\n",
       "        0.97368421, 0.98245614, 0.93859649, 0.97368421, 0.98245614,\n",
       "        0.63157895, 0.97368421, 0.98245614, 0.63157895, 0.97368421,\n",
       "        0.83333333, 0.95614035, 0.97368421, 0.84210526, 0.93859649,\n",
       "        0.97368421, 0.84210526, 0.63157895, 0.97368421, 0.84210526,\n",
       "        0.63157895, 0.97368421, 0.96491228, 0.95614035, 0.97368421,\n",
       "        0.97368421, 0.93859649, 0.97368421, 0.97368421, 0.63157895,\n",
       "        0.97368421, 0.97368421, 0.63157895, 0.97368421, 0.80701754,\n",
       "        0.95614035, 0.97368421, 0.76315789, 0.93859649, 0.97368421,\n",
       "        0.76315789, 0.63157895, 0.97368421, 0.76315789, 0.63157895,\n",
       "        0.97368421, 0.99122807, 0.95614035, 0.95614035, 0.99122807,\n",
       "        0.93859649, 0.95614035, 0.99122807, 0.63157895, 0.95614035,\n",
       "        0.99122807, 0.63157895, 0.95614035, 0.87719298, 0.95614035,\n",
       "        0.95614035, 0.88596491, 0.93859649, 0.95614035, 0.88596491,\n",
       "        0.63157895, 0.95614035, 0.88596491, 0.63157895, 0.95614035,\n",
       "        0.98245614, 0.95614035, 0.95614035, 0.98245614, 0.93859649,\n",
       "        0.95614035, 0.98245614, 0.63157895, 0.95614035, 0.98245614,\n",
       "        0.63157895, 0.95614035, 0.8245614 , 0.95614035, 0.95614035,\n",
       "        0.84210526, 0.93859649, 0.95614035, 0.84210526, 0.63157895,\n",
       "        0.95614035, 0.84210526, 0.63157895, 0.95614035, 0.96491228,\n",
       "        0.95614035, 0.95614035, 0.97368421, 0.93859649, 0.95614035,\n",
       "        0.97368421, 0.63157895, 0.95614035, 0.97368421, 0.63157895,\n",
       "        0.95614035, 0.8245614 , 0.95614035, 0.95614035, 0.76315789,\n",
       "        0.93859649, 0.95614035, 0.76315789, 0.63157895, 0.95614035,\n",
       "        0.76315789, 0.63157895, 0.95614035, 0.99122807, 0.95614035,\n",
       "        0.95614035, 0.99122807, 0.93859649, 0.95614035, 0.99122807,\n",
       "        0.63157895, 0.95614035, 0.99122807, 0.63157895, 0.95614035,\n",
       "        0.88596491, 0.95614035, 0.95614035, 0.88596491, 0.93859649,\n",
       "        0.95614035, 0.88596491, 0.63157895, 0.95614035, 0.88596491,\n",
       "        0.63157895, 0.95614035, 0.98245614, 0.95614035, 0.95614035,\n",
       "        0.98245614, 0.93859649, 0.95614035, 0.98245614, 0.63157895,\n",
       "        0.95614035, 0.98245614, 0.63157895, 0.95614035, 0.80701754,\n",
       "        0.95614035, 0.95614035, 0.84210526, 0.93859649, 0.95614035,\n",
       "        0.84210526, 0.63157895, 0.95614035, 0.84210526, 0.63157895,\n",
       "        0.95614035, 0.96491228, 0.95614035, 0.95614035, 0.97368421,\n",
       "        0.93859649, 0.95614035, 0.97368421, 0.63157895, 0.95614035,\n",
       "        0.97368421, 0.63157895, 0.95614035, 0.78947368, 0.95614035,\n",
       "        0.95614035, 0.76315789, 0.93859649, 0.95614035, 0.76315789,\n",
       "        0.63157895, 0.95614035, 0.76315789, 0.63157895, 0.95614035]),\n",
       " 'split3_test_score': array([0.96491228, 0.97368421, 0.96491228, 0.95614035, 0.96491228,\n",
       "        0.96491228, 0.95614035, 0.64035088, 0.96491228, 0.95614035,\n",
       "        0.63157895, 0.96491228, 0.93859649, 0.97368421, 0.96491228,\n",
       "        0.86842105, 0.96491228, 0.96491228, 0.86842105, 0.64035088,\n",
       "        0.96491228, 0.86842105, 0.63157895, 0.96491228, 0.95614035,\n",
       "        0.97368421, 0.96491228, 0.92982456, 0.96491228, 0.96491228,\n",
       "        0.92982456, 0.64035088, 0.96491228, 0.92982456, 0.63157895,\n",
       "        0.96491228, 0.92105263, 0.97368421, 0.96491228, 0.83333333,\n",
       "        0.96491228, 0.96491228, 0.83333333, 0.64035088, 0.96491228,\n",
       "        0.83333333, 0.63157895, 0.96491228, 0.93859649, 0.97368421,\n",
       "        0.96491228, 0.92105263, 0.96491228, 0.96491228, 0.92105263,\n",
       "        0.64035088, 0.96491228, 0.92105263, 0.63157895, 0.96491228,\n",
       "        0.90350877, 0.97368421, 0.96491228, 0.83333333, 0.96491228,\n",
       "        0.96491228, 0.83333333, 0.64035088, 0.96491228, 0.83333333,\n",
       "        0.63157895, 0.96491228, 0.97368421, 0.98245614, 0.98245614,\n",
       "        0.95614035, 0.97368421, 0.98245614, 0.95614035, 0.64035088,\n",
       "        0.98245614, 0.95614035, 0.63157895, 0.98245614, 0.92982456,\n",
       "        0.98245614, 0.98245614, 0.86842105, 0.97368421, 0.98245614,\n",
       "        0.86842105, 0.64035088, 0.98245614, 0.86842105, 0.63157895,\n",
       "        0.98245614, 0.97368421, 0.98245614, 0.98245614, 0.92982456,\n",
       "        0.97368421, 0.98245614, 0.92982456, 0.64035088, 0.98245614,\n",
       "        0.92982456, 0.63157895, 0.98245614, 0.92105263, 0.98245614,\n",
       "        0.98245614, 0.83333333, 0.97368421, 0.98245614, 0.83333333,\n",
       "        0.64035088, 0.98245614, 0.83333333, 0.63157895, 0.98245614,\n",
       "        0.95614035, 0.98245614, 0.98245614, 0.92105263, 0.97368421,\n",
       "        0.98245614, 0.92105263, 0.64035088, 0.98245614, 0.92105263,\n",
       "        0.63157895, 0.98245614, 0.89473684, 0.98245614, 0.98245614,\n",
       "        0.83333333, 0.97368421, 0.98245614, 0.83333333, 0.64035088,\n",
       "        0.98245614, 0.83333333, 0.63157895, 0.98245614, 0.98245614,\n",
       "        0.97368421, 0.97368421, 0.95614035, 0.97368421, 0.97368421,\n",
       "        0.95614035, 0.64035088, 0.97368421, 0.95614035, 0.63157895,\n",
       "        0.97368421, 0.93859649, 0.97368421, 0.97368421, 0.86842105,\n",
       "        0.97368421, 0.97368421, 0.86842105, 0.64035088, 0.97368421,\n",
       "        0.86842105, 0.63157895, 0.97368421, 0.97368421, 0.97368421,\n",
       "        0.97368421, 0.92982456, 0.97368421, 0.97368421, 0.92982456,\n",
       "        0.64035088, 0.97368421, 0.92982456, 0.63157895, 0.97368421,\n",
       "        0.92105263, 0.97368421, 0.97368421, 0.83333333, 0.97368421,\n",
       "        0.97368421, 0.83333333, 0.64035088, 0.97368421, 0.83333333,\n",
       "        0.63157895, 0.97368421, 0.96491228, 0.97368421, 0.97368421,\n",
       "        0.92105263, 0.97368421, 0.97368421, 0.92105263, 0.64035088,\n",
       "        0.97368421, 0.92105263, 0.63157895, 0.97368421, 0.87719298,\n",
       "        0.97368421, 0.97368421, 0.83333333, 0.97368421, 0.97368421,\n",
       "        0.83333333, 0.64035088, 0.97368421, 0.83333333, 0.63157895,\n",
       "        0.97368421, 0.96491228, 0.95614035, 0.96491228, 0.95614035,\n",
       "        0.97368421, 0.96491228, 0.95614035, 0.64035088, 0.96491228,\n",
       "        0.95614035, 0.63157895, 0.96491228, 0.90350877, 0.95614035,\n",
       "        0.96491228, 0.86842105, 0.97368421, 0.96491228, 0.86842105,\n",
       "        0.64035088, 0.96491228, 0.86842105, 0.63157895, 0.96491228,\n",
       "        0.96491228, 0.95614035, 0.96491228, 0.92982456, 0.97368421,\n",
       "        0.96491228, 0.92982456, 0.64035088, 0.96491228, 0.92982456,\n",
       "        0.63157895, 0.96491228, 0.87719298, 0.95614035, 0.96491228,\n",
       "        0.83333333, 0.97368421, 0.96491228, 0.83333333, 0.64035088,\n",
       "        0.96491228, 0.83333333, 0.63157895, 0.96491228, 0.96491228,\n",
       "        0.95614035, 0.96491228, 0.92105263, 0.97368421, 0.96491228,\n",
       "        0.92105263, 0.64035088, 0.96491228, 0.92105263, 0.63157895,\n",
       "        0.96491228, 0.85087719, 0.95614035, 0.96491228, 0.83333333,\n",
       "        0.97368421, 0.96491228, 0.83333333, 0.64035088, 0.96491228,\n",
       "        0.83333333, 0.63157895, 0.96491228, 0.95614035, 0.95614035,\n",
       "        0.96491228, 0.95614035, 0.97368421, 0.96491228, 0.95614035,\n",
       "        0.64035088, 0.96491228, 0.95614035, 0.63157895, 0.96491228,\n",
       "        0.87719298, 0.95614035, 0.96491228, 0.86842105, 0.97368421,\n",
       "        0.96491228, 0.86842105, 0.64035088, 0.96491228, 0.86842105,\n",
       "        0.63157895, 0.96491228, 0.96491228, 0.95614035, 0.96491228,\n",
       "        0.92982456, 0.97368421, 0.96491228, 0.92982456, 0.64035088,\n",
       "        0.96491228, 0.92982456, 0.63157895, 0.96491228, 0.85964912,\n",
       "        0.95614035, 0.96491228, 0.83333333, 0.97368421, 0.96491228,\n",
       "        0.83333333, 0.64035088, 0.96491228, 0.83333333, 0.63157895,\n",
       "        0.96491228, 0.96491228, 0.95614035, 0.96491228, 0.92105263,\n",
       "        0.97368421, 0.96491228, 0.92105263, 0.64035088, 0.96491228,\n",
       "        0.92105263, 0.63157895, 0.96491228, 0.86842105, 0.95614035,\n",
       "        0.96491228, 0.83333333, 0.97368421, 0.96491228, 0.83333333,\n",
       "        0.64035088, 0.96491228, 0.83333333, 0.63157895, 0.96491228]),\n",
       " 'split4_test_score': array([0.97345133, 0.96460177, 0.98230088, 0.92035398, 0.89380531,\n",
       "        0.98230088, 0.92035398, 0.62831858, 0.98230088, 0.92035398,\n",
       "        0.62831858, 0.98230088, 0.91150442, 0.96460177, 0.98230088,\n",
       "        0.90265487, 0.89380531, 0.98230088, 0.90265487, 0.62831858,\n",
       "        0.98230088, 0.90265487, 0.62831858, 0.98230088, 0.96460177,\n",
       "        0.96460177, 0.98230088, 0.91150442, 0.89380531, 0.98230088,\n",
       "        0.91150442, 0.62831858, 0.98230088, 0.91150442, 0.62831858,\n",
       "        0.98230088, 0.87610619, 0.96460177, 0.98230088, 0.84070796,\n",
       "        0.89380531, 0.98230088, 0.84070796, 0.62831858, 0.98230088,\n",
       "        0.84070796, 0.62831858, 0.98230088, 0.9380531 , 0.96460177,\n",
       "        0.98230088, 0.90265487, 0.89380531, 0.98230088, 0.90265487,\n",
       "        0.62831858, 0.98230088, 0.90265487, 0.62831858, 0.98230088,\n",
       "        0.85840708, 0.96460177, 0.98230088, 0.7699115 , 0.89380531,\n",
       "        0.98230088, 0.7699115 , 0.62831858, 0.98230088, 0.7699115 ,\n",
       "        0.62831858, 0.98230088, 0.96460177, 0.94690265, 0.99115044,\n",
       "        0.92035398, 0.90265487, 0.99115044, 0.92035398, 0.62831858,\n",
       "        0.99115044, 0.92035398, 0.62831858, 0.99115044, 0.91150442,\n",
       "        0.94690265, 0.99115044, 0.90265487, 0.90265487, 0.99115044,\n",
       "        0.90265487, 0.62831858, 0.99115044, 0.90265487, 0.62831858,\n",
       "        0.99115044, 0.96460177, 0.94690265, 0.99115044, 0.91150442,\n",
       "        0.90265487, 0.99115044, 0.91150442, 0.62831858, 0.99115044,\n",
       "        0.91150442, 0.62831858, 0.99115044, 0.91150442, 0.94690265,\n",
       "        0.99115044, 0.84070796, 0.90265487, 0.99115044, 0.84070796,\n",
       "        0.62831858, 0.99115044, 0.84070796, 0.62831858, 0.99115044,\n",
       "        0.95575221, 0.94690265, 0.99115044, 0.90265487, 0.90265487,\n",
       "        0.99115044, 0.90265487, 0.62831858, 0.99115044, 0.90265487,\n",
       "        0.62831858, 0.99115044, 0.84955752, 0.94690265, 0.99115044,\n",
       "        0.7699115 , 0.90265487, 0.99115044, 0.7699115 , 0.62831858,\n",
       "        0.99115044, 0.7699115 , 0.62831858, 0.99115044, 0.95575221,\n",
       "        0.9380531 , 1.        , 0.92035398, 0.90265487, 1.        ,\n",
       "        0.92035398, 0.62831858, 1.        , 0.92035398, 0.62831858,\n",
       "        1.        , 0.92035398, 0.9380531 , 1.        , 0.90265487,\n",
       "        0.90265487, 1.        , 0.90265487, 0.62831858, 1.        ,\n",
       "        0.90265487, 0.62831858, 1.        , 0.95575221, 0.9380531 ,\n",
       "        1.        , 0.91150442, 0.90265487, 1.        , 0.91150442,\n",
       "        0.62831858, 1.        , 0.91150442, 0.62831858, 1.        ,\n",
       "        0.92035398, 0.9380531 , 1.        , 0.84070796, 0.90265487,\n",
       "        1.        , 0.84070796, 0.62831858, 1.        , 0.84070796,\n",
       "        0.62831858, 1.        , 0.96460177, 0.9380531 , 1.        ,\n",
       "        0.90265487, 0.90265487, 1.        , 0.90265487, 0.62831858,\n",
       "        1.        , 0.90265487, 0.62831858, 1.        , 0.84955752,\n",
       "        0.9380531 , 1.        , 0.7699115 , 0.90265487, 1.        ,\n",
       "        0.7699115 , 0.62831858, 1.        , 0.7699115 , 0.62831858,\n",
       "        1.        , 0.94690265, 0.94690265, 1.        , 0.92035398,\n",
       "        0.90265487, 1.        , 0.92035398, 0.62831858, 1.        ,\n",
       "        0.92035398, 0.62831858, 1.        , 0.91150442, 0.94690265,\n",
       "        1.        , 0.90265487, 0.90265487, 1.        , 0.90265487,\n",
       "        0.62831858, 1.        , 0.90265487, 0.62831858, 1.        ,\n",
       "        0.95575221, 0.94690265, 1.        , 0.91150442, 0.90265487,\n",
       "        1.        , 0.91150442, 0.62831858, 1.        , 0.91150442,\n",
       "        0.62831858, 1.        , 0.87610619, 0.94690265, 1.        ,\n",
       "        0.84070796, 0.90265487, 1.        , 0.84070796, 0.62831858,\n",
       "        1.        , 0.84070796, 0.62831858, 1.        , 0.94690265,\n",
       "        0.94690265, 1.        , 0.90265487, 0.90265487, 1.        ,\n",
       "        0.90265487, 0.62831858, 1.        , 0.90265487, 0.62831858,\n",
       "        1.        , 0.85840708, 0.94690265, 1.        , 0.7699115 ,\n",
       "        0.90265487, 1.        , 0.7699115 , 0.62831858, 1.        ,\n",
       "        0.7699115 , 0.62831858, 1.        , 0.92035398, 0.94690265,\n",
       "        1.        , 0.92035398, 0.90265487, 1.        , 0.92035398,\n",
       "        0.62831858, 1.        , 0.92035398, 0.62831858, 1.        ,\n",
       "        0.90265487, 0.94690265, 1.        , 0.90265487, 0.90265487,\n",
       "        1.        , 0.90265487, 0.62831858, 1.        , 0.90265487,\n",
       "        0.62831858, 1.        , 0.92035398, 0.94690265, 1.        ,\n",
       "        0.91150442, 0.90265487, 1.        , 0.91150442, 0.62831858,\n",
       "        1.        , 0.91150442, 0.62831858, 1.        , 0.87610619,\n",
       "        0.94690265, 1.        , 0.84070796, 0.90265487, 1.        ,\n",
       "        0.84070796, 0.62831858, 1.        , 0.84070796, 0.62831858,\n",
       "        1.        , 0.94690265, 0.94690265, 1.        , 0.90265487,\n",
       "        0.90265487, 1.        , 0.90265487, 0.62831858, 1.        ,\n",
       "        0.90265487, 0.62831858, 1.        , 0.85840708, 0.94690265,\n",
       "        1.        , 0.7699115 , 0.90265487, 1.        , 0.7699115 ,\n",
       "        0.62831858, 1.        , 0.7699115 , 0.62831858, 1.        ]),\n",
       " 'mean_test_score': array([0.95609377, 0.96309579, 0.97365316, 0.95073746, 0.91560317,\n",
       "        0.97365316, 0.95073746, 0.63092687, 0.97365316, 0.95073746,\n",
       "        0.6274181 , 0.97365316, 0.90686229, 0.96309579, 0.97365316,\n",
       "        0.87877659, 0.91560317, 0.97365316, 0.87877659, 0.63092687,\n",
       "        0.97365316, 0.87877659, 0.6274181 , 0.97365316, 0.93853439,\n",
       "        0.96309579, 0.97365316, 0.93317808, 0.91560317, 0.97365316,\n",
       "        0.93317808, 0.63092687, 0.97365316, 0.93317808, 0.6274181 ,\n",
       "        0.97365316, 0.88574755, 0.96309579, 0.97365316, 0.83831703,\n",
       "        0.91560317, 0.97365316, 0.83831703, 0.63092687, 0.97365316,\n",
       "        0.83831703, 0.6274181 , 0.97365316, 0.92094395, 0.96309579,\n",
       "        0.97365316, 0.92789939, 0.91560317, 0.97365316, 0.92789939,\n",
       "        0.63092687, 0.97365316, 0.92789939, 0.6274181 , 0.97365316,\n",
       "        0.8611551 , 0.96309579, 0.97365316, 0.79608756, 0.91560317,\n",
       "        0.97365316, 0.79608756, 0.63092687, 0.97365316, 0.79608756,\n",
       "        0.6274181 , 0.97365316, 0.97011334, 0.95780158, 0.97015991,\n",
       "        0.95073746, 0.92088185, 0.97015991, 0.95073746, 0.63092687,\n",
       "        0.97015991, 0.95073746, 0.6274181 , 0.97015991, 0.90861667,\n",
       "        0.95780158, 0.97015991, 0.87877659, 0.92088185, 0.97015991,\n",
       "        0.87877659, 0.63092687, 0.97015991, 0.87877659, 0.6274181 ,\n",
       "        0.97015991, 0.95081509, 0.95780158, 0.97015991, 0.93317808,\n",
       "        0.92088185, 0.97015991, 0.93317808, 0.63092687, 0.97015991,\n",
       "        0.93317808, 0.6274181 , 0.97015991, 0.88756404, 0.95780158,\n",
       "        0.97015991, 0.83831703, 0.92088185, 0.97015991, 0.83831703,\n",
       "        0.63092687, 0.97015991, 0.83831703, 0.6274181 , 0.97015991,\n",
       "        0.93676448, 0.95780158, 0.97015991, 0.92789939, 0.92088185,\n",
       "        0.97015991, 0.92789939, 0.63092687, 0.97015991, 0.92789939,\n",
       "        0.6274181 , 0.97015991, 0.8453501 , 0.95780158, 0.97015991,\n",
       "        0.79608756, 0.92088185, 0.97015991, 0.79608756, 0.63092687,\n",
       "        0.97015991, 0.79608756, 0.6274181 , 0.97015991, 0.9718522 ,\n",
       "        0.95076851, 0.97192982, 0.95073746, 0.92088185, 0.97192982,\n",
       "        0.95073746, 0.63092687, 0.97192982, 0.95073746, 0.6274181 ,\n",
       "        0.97192982, 0.9086322 , 0.95076851, 0.97192982, 0.87877659,\n",
       "        0.92088185, 0.97192982, 0.87877659, 0.63092687, 0.97192982,\n",
       "        0.87877659, 0.6274181 , 0.97192982, 0.95079957, 0.95076851,\n",
       "        0.97192982, 0.93317808, 0.92088185, 0.97192982, 0.93317808,\n",
       "        0.63092687, 0.97192982, 0.93317808, 0.6274181 , 0.97192982,\n",
       "        0.88056202, 0.95076851, 0.97192982, 0.83831703, 0.92088185,\n",
       "        0.97192982, 0.83831703, 0.63092687, 0.97192982, 0.83831703,\n",
       "        0.6274181 , 0.97192982, 0.94555193, 0.95076851, 0.97192982,\n",
       "        0.92789939, 0.92088185, 0.97192982, 0.92789939, 0.63092687,\n",
       "        0.97192982, 0.92789939, 0.6274181 , 0.97192982, 0.84184133,\n",
       "        0.95076851, 0.97192982, 0.79608756, 0.92088185, 0.97192982,\n",
       "        0.79608756, 0.63092687, 0.97192982, 0.79608756, 0.6274181 ,\n",
       "        0.97192982, 0.95955597, 0.94552088, 0.96315789, 0.95073746,\n",
       "        0.92088185, 0.96315789, 0.95073746, 0.63092687, 0.96315789,\n",
       "        0.95073746, 0.6274181 , 0.96315789, 0.89107281, 0.94552088,\n",
       "        0.96315789, 0.87877659, 0.92088185, 0.96315789, 0.87877659,\n",
       "        0.63092687, 0.96315789, 0.87877659, 0.6274181 , 0.96315789,\n",
       "        0.95430834, 0.94552088, 0.96315789, 0.93317808, 0.92088185,\n",
       "        0.96315789, 0.93317808, 0.63092687, 0.96315789, 0.93317808,\n",
       "        0.6274181 , 0.96315789, 0.85416861, 0.94552088, 0.96315789,\n",
       "        0.83831703, 0.92088185, 0.96315789, 0.83831703, 0.63092687,\n",
       "        0.96315789, 0.83831703, 0.6274181 , 0.96315789, 0.93674895,\n",
       "        0.94552088, 0.96315789, 0.92789939, 0.92088185, 0.96315789,\n",
       "        0.92789939, 0.63092687, 0.96315789, 0.92789939, 0.6274181 ,\n",
       "        0.96315789, 0.83133054, 0.94552088, 0.96315789, 0.79608756,\n",
       "        0.92088185, 0.96315789, 0.79608756, 0.63092687, 0.96315789,\n",
       "        0.79608756, 0.6274181 , 0.96315789, 0.95073746, 0.94552088,\n",
       "        0.95964912, 0.95073746, 0.92088185, 0.95964912, 0.95073746,\n",
       "        0.63092687, 0.95964912, 0.95073746, 0.6274181 , 0.95964912,\n",
       "        0.88228536, 0.94552088, 0.95964912, 0.87877659, 0.92088185,\n",
       "        0.95964912, 0.87877659, 0.63092687, 0.95964912, 0.87877659,\n",
       "        0.6274181 , 0.95964912, 0.94722869, 0.94552088, 0.95964912,\n",
       "        0.93317808, 0.92088185, 0.95964912, 0.93317808, 0.63092687,\n",
       "        0.95964912, 0.93317808, 0.6274181 , 0.95964912, 0.85241422,\n",
       "        0.94552088, 0.95964912, 0.83831703, 0.92088185, 0.95964912,\n",
       "        0.83831703, 0.63092687, 0.95964912, 0.83831703, 0.6274181 ,\n",
       "        0.95964912, 0.93674895, 0.94552088, 0.95964912, 0.92789939,\n",
       "        0.92088185, 0.95964912, 0.92789939, 0.63092687, 0.95964912,\n",
       "        0.92789939, 0.6274181 , 0.95964912, 0.82431299, 0.94552088,\n",
       "        0.95964912, 0.79608756, 0.92088185, 0.95964912, 0.79608756,\n",
       "        0.63092687, 0.95964912, 0.79608756, 0.6274181 , 0.95964912]),\n",
       " 'std_test_score': array([0.01563982, 0.00654887, 0.00549889, 0.02345459, 0.02980359,\n",
       "        0.00549889, 0.02345459, 0.00569908, 0.00549889, 0.02345459,\n",
       "        0.00394868, 0.00549889, 0.01801989, 0.00654887, 0.00549889,\n",
       "        0.01765859, 0.02980359, 0.00549889, 0.01765859, 0.00569908,\n",
       "        0.00549889, 0.01765859, 0.00394868, 0.00549889, 0.022118  ,\n",
       "        0.00654887, 0.00549889, 0.02591242, 0.02980359, 0.00549889,\n",
       "        0.02591242, 0.00569908, 0.00549889, 0.02591242, 0.00394868,\n",
       "        0.00549889, 0.01850859, 0.00654887, 0.00549889, 0.00885302,\n",
       "        0.02980359, 0.00549889, 0.00885302, 0.00569908, 0.00549889,\n",
       "        0.00885302, 0.00394868, 0.00549889, 0.01653004, 0.00654887,\n",
       "        0.00549889, 0.0246092 , 0.02980359, 0.00549889, 0.0246092 ,\n",
       "        0.00569908, 0.00549889, 0.0246092 , 0.00394868, 0.00549889,\n",
       "        0.02249198, 0.00654887, 0.00549889, 0.0266444 , 0.02980359,\n",
       "        0.00549889, 0.0266444 , 0.00569908, 0.00549889, 0.0266444 ,\n",
       "        0.00394868, 0.00549889, 0.01315408, 0.01410601, 0.01422978,\n",
       "        0.02345459, 0.03517466, 0.01422978, 0.02345459, 0.00569908,\n",
       "        0.01422978, 0.02345459, 0.00394868, 0.01422978, 0.01309075,\n",
       "        0.01410601, 0.01422978, 0.01765859, 0.03517466, 0.01422978,\n",
       "        0.01765859, 0.00569908, 0.01422978, 0.01765859, 0.00394868,\n",
       "        0.01422978, 0.02964023, 0.01410601, 0.01422978, 0.02591242,\n",
       "        0.03517466, 0.01422978, 0.02591242, 0.00569908, 0.01422978,\n",
       "        0.02591242, 0.00394868, 0.01422978, 0.02611346, 0.01410601,\n",
       "        0.01422978, 0.00885302, 0.03517466, 0.01422978, 0.00885302,\n",
       "        0.00569908, 0.01422978, 0.00885302, 0.00394868, 0.01422978,\n",
       "        0.02735011, 0.01410601, 0.01422978, 0.0246092 , 0.03517466,\n",
       "        0.01422978, 0.0246092 , 0.00569908, 0.01422978, 0.0246092 ,\n",
       "        0.00394868, 0.01422978, 0.02632677, 0.01410601, 0.01422978,\n",
       "        0.0266444 , 0.03517466, 0.01422978, 0.0266444 , 0.00569908,\n",
       "        0.01422978, 0.0266444 , 0.00394868, 0.01422978, 0.01298771,\n",
       "        0.01323168, 0.01607921, 0.02345459, 0.03517466, 0.01607921,\n",
       "        0.02345459, 0.00569908, 0.01607921, 0.02345459, 0.00394868,\n",
       "        0.01607921, 0.02037735, 0.01323168, 0.01607921, 0.01765859,\n",
       "        0.03517466, 0.01607921, 0.01765859, 0.00569908, 0.01607921,\n",
       "        0.01765859, 0.00394868, 0.01607921, 0.03400715, 0.01323168,\n",
       "        0.01607921, 0.02591242, 0.03517466, 0.01607921, 0.02591242,\n",
       "        0.00569908, 0.01607921, 0.02591242, 0.00394868, 0.01607921,\n",
       "        0.03562577, 0.01323168, 0.01607921, 0.00885302, 0.03517466,\n",
       "        0.01607921, 0.00885302, 0.00569908, 0.01607921, 0.00885302,\n",
       "        0.00394868, 0.01607921, 0.0273609 , 0.01323168, 0.01607921,\n",
       "        0.0246092 , 0.03517466, 0.01607921, 0.0246092 , 0.00569908,\n",
       "        0.01607921, 0.0246092 , 0.00394868, 0.01607921, 0.02277907,\n",
       "        0.01323168, 0.01607921, 0.0266444 , 0.03517466, 0.01607921,\n",
       "        0.0266444 , 0.00569908, 0.01607921, 0.0266444 , 0.00394868,\n",
       "        0.01607921, 0.01725683, 0.01288072, 0.02030849, 0.02345459,\n",
       "        0.03517466, 0.02030849, 0.02345459, 0.00569908, 0.02030849,\n",
       "        0.02345459, 0.00394868, 0.02030849, 0.01402493, 0.01288072,\n",
       "        0.02030849, 0.01765859, 0.03517466, 0.02030849, 0.01765859,\n",
       "        0.00569908, 0.02030849, 0.01765859, 0.00394868, 0.02030849,\n",
       "        0.02313658, 0.01288072, 0.02030849, 0.02591242, 0.03517466,\n",
       "        0.02030849, 0.02591242, 0.00569908, 0.02030849, 0.02591242,\n",
       "        0.00394868, 0.02030849, 0.02168922, 0.01288072, 0.02030849,\n",
       "        0.00885302, 0.03517466, 0.02030849, 0.00885302, 0.00569908,\n",
       "        0.02030849, 0.00885302, 0.00394868, 0.02030849, 0.03566948,\n",
       "        0.01288072, 0.02030849, 0.0246092 , 0.03517466, 0.02030849,\n",
       "        0.0246092 , 0.00569908, 0.02030849, 0.0246092 , 0.00394868,\n",
       "        0.02030849, 0.02771426, 0.01288072, 0.02030849, 0.0266444 ,\n",
       "        0.03517466, 0.02030849, 0.0266444 , 0.00569908, 0.02030849,\n",
       "        0.0266444 , 0.00394868, 0.02030849, 0.02345459, 0.01288072,\n",
       "        0.02327456, 0.02345459, 0.03517466, 0.02327456, 0.02345459,\n",
       "        0.00569908, 0.02327456, 0.02345459, 0.00394868, 0.02327456,\n",
       "        0.01400233, 0.01288072, 0.02327456, 0.01765859, 0.03517466,\n",
       "        0.02327456, 0.01765859, 0.00569908, 0.02327456, 0.01765859,\n",
       "        0.00394868, 0.02327456, 0.02433573, 0.01288072, 0.02327456,\n",
       "        0.02591242, 0.03517466, 0.02327456, 0.02591242, 0.00569908,\n",
       "        0.02327456, 0.02591242, 0.00394868, 0.02327456, 0.02605676,\n",
       "        0.01288072, 0.02327456, 0.00885302, 0.03517466, 0.02327456,\n",
       "        0.00885302, 0.00569908, 0.02327456, 0.00885302, 0.00394868,\n",
       "        0.02327456, 0.03566948, 0.01288072, 0.02327456, 0.0246092 ,\n",
       "        0.03517466, 0.02327456, 0.0246092 , 0.00569908, 0.02327456,\n",
       "        0.0246092 , 0.00394868, 0.02327456, 0.04093462, 0.01288072,\n",
       "        0.02327456, 0.0266444 , 0.03517466, 0.02327456, 0.0266444 ,\n",
       "        0.00569908, 0.02327456, 0.0266444 , 0.00394868, 0.02327456]),\n",
       " 'rank_test_score': array([136,  99,   1, 146, 235,   1, 146, 301,   1, 146, 331,   1, 243,\n",
       "         99,   1, 249, 235,   1, 249, 301,   1, 249, 331,   1, 176,  99,\n",
       "          1, 180, 235,   1, 180, 301,   1, 180, 331,   1, 246,  99,   1,\n",
       "        269, 235,   1, 269, 301,   1, 269, 331,   1, 210,  99,   1, 195,\n",
       "        235,   1, 195, 301,   1, 195, 331,   1, 264,  99,   1, 286, 235,\n",
       "          1, 286, 301,   1, 286, 331,   1,  74, 130,  50, 146, 211,  50,\n",
       "        146, 301,  50, 146, 331,  50, 242, 130,  50, 249, 211,  50, 249,\n",
       "        301,  50, 249, 331,  50, 138, 130,  50, 180, 211,  50, 180, 301,\n",
       "         50, 180, 331,  50, 245, 130,  50, 269, 211,  50, 269, 301,  50,\n",
       "        269, 331,  50, 177, 130,  50, 195, 211,  50, 195, 301,  50, 195,\n",
       "        331,  50, 267, 130,  50, 286, 211,  50, 286, 301,  50, 286, 331,\n",
       "         50,  49, 140,  25, 146, 211,  25, 146, 301,  25, 146, 331,  25,\n",
       "        241, 140,  25, 249, 211,  25, 249, 301,  25, 249, 331,  25, 139,\n",
       "        140,  25, 180, 211,  25, 180, 301,  25, 180, 331,  25, 248, 140,\n",
       "         25, 269, 211,  25, 269, 301,  25, 269, 331,  25, 163, 140,  25,\n",
       "        195, 211,  25, 195, 301,  25, 195, 331,  25, 268, 140,  25, 286,\n",
       "        211,  25, 286, 301,  25, 286, 331,  25, 129, 164,  75, 146, 211,\n",
       "         75, 146, 301,  75, 146, 331,  75, 244, 164,  75, 249, 211,  75,\n",
       "        249, 301,  75, 249, 331,  75, 137, 164,  75, 180, 211,  75, 180,\n",
       "        301,  75, 180, 331,  75, 265, 164,  75, 269, 211,  75, 269, 301,\n",
       "         75, 269, 331,  75, 178, 164,  75, 195, 211,  75, 195, 301,  75,\n",
       "        195, 331,  75, 284, 164,  75, 286, 211,  75, 286, 301,  75, 286,\n",
       "        331,  75, 146, 164, 105, 146, 211, 105, 146, 301, 105, 146, 331,\n",
       "        105, 247, 164, 105, 249, 211, 105, 249, 301, 105, 249, 331, 105,\n",
       "        162, 164, 105, 180, 211, 105, 180, 301, 105, 180, 331, 105, 266,\n",
       "        164, 105, 269, 211, 105, 269, 301, 105, 269, 331, 105, 178, 164,\n",
       "        105, 195, 211, 105, 195, 301, 105, 195, 331, 105, 285, 164, 105,\n",
       "        286, 211, 105, 286, 301, 105, 286, 331, 105])}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fe3f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7bf0e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ebc66b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svc_model.pickle', 'wb') as handle:\n",
    "    pickle.dump(best_clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e485639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could simply load a previously saved/created model as start predictions\n",
    "\n",
    "with open('svc_model.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "50397cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                ('svc', SVC(C=1, gamma=0.1, kernel='linear'))])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2456d548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876977152899824"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.score(cancer_data.data, cancer_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79d5eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= b.predict(cancer_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2b447db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9876977152899824\n",
      "Precision Score: 0.9882708665603402\n",
      "Recall Score: 0.985406426721632\n",
      "f1 Score: 0.9868050103194559\n",
      "\n",
      " \n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       212\n",
      "           1       0.99      0.99      0.99       357\n",
      "\n",
      "    accuracy                           0.99       569\n",
      "   macro avg       0.99      0.99      0.99       569\n",
      "weighted avg       0.99      0.99      0.99       569\n",
      "\n",
      "\n",
      " \n",
      "Confusion Matrix:\n",
      "\n",
      "[[207   5]\n",
      " [  2 355]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_reports(cancer_data.target, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f9fae",
   "metadata": {},
   "source": [
    "## Validation Curve\n",
    "\n",
    "1. To validate a model against one parameter change we will a scoring function\n",
    "2. Create a grid of possible hyperparameters configurations\n",
    "3. Select the hyperparamneters which gives the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c81c6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "import numpy as np\n",
    "\n",
    "param_range = np.arange(5,150,5)\n",
    "\n",
    "train_score, test_score = validation_curve(RandomForestClassifier(),\n",
    "                                          digits.data,\n",
    "                                          digits.target,\n",
    "                                          param_name='n_estimators',\n",
    "                                          param_range=param_range, \n",
    "                                          cv=5,\n",
    "                                          scoring='recall_macro',\n",
    "                                          n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "71d0ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83014157 0.81416774 0.85760492 0.87933934 0.85517375]\n",
      " [0.9109438  0.86131489 0.93797499 0.92657872 0.89524024]\n",
      " [0.90817031 0.85266838 0.94653784 0.94649936 0.872855  ]\n",
      " [0.91087302 0.88902188 0.94973503 0.95190047 0.92249678]\n",
      " [0.91055556 0.89410982 0.9471074  0.95761476 0.92781424]\n",
      " [0.94150794 0.86933934 0.95226108 0.95753539 0.93083012]\n",
      " [0.92768983 0.89757615 0.96083289 0.958003   0.91669884]\n",
      " [0.93324968 0.89735521 0.94099553 0.96031317 0.91700343]\n",
      " [0.93587302 0.91689189 0.95520226 0.96626126 0.92264264]\n",
      " [0.9247619  0.90832046 0.96068274 0.96626126 0.90905405]\n",
      " [0.9302381  0.9195903  0.95781664 0.95499142 0.92557486]\n",
      " [0.93324968 0.9060725  0.96068274 0.96332475 0.9281982 ]\n",
      " [0.92761476 0.9003668  0.95249956 0.96649507 0.93090519]\n",
      " [0.92468254 0.90855427 0.95488871 0.96634063 0.9309009 ]\n",
      " [0.93031746 0.91425568 0.95774157 0.96649507 0.928432  ]\n",
      " [0.93587302 0.91433934 0.95503886 0.96317031 0.91986057]\n",
      " [0.93873016 0.9141849  0.96369899 0.96610682 0.93638567]\n",
      " [0.93039683 0.9225976  0.95511394 0.96355856 0.91453453]\n",
      " [0.93309524 0.91973616 0.95790496 0.96062634 0.9336036 ]\n",
      " [0.92475761 0.91140712 0.96075782 0.96903904 0.92812312]\n",
      " [0.93309524 0.88918061 0.95503886 0.96347919 0.93900901]\n",
      " [0.93309524 0.90854569 0.95781664 0.96626126 0.92549979]\n",
      " [0.93031746 0.91156156 0.95781664 0.97212999 0.93885886]\n",
      " [0.93587302 0.91425997 0.96322205 0.96062205 0.92542042]\n",
      " [0.9247619  0.92244316 0.94939498 0.9691184  0.92827756]\n",
      " [0.93301587 0.90299013 0.95781664 0.96347919 0.92851137]\n",
      " [0.93865079 0.90307379 0.96075782 0.96332475 0.92812312]\n",
      " [0.93039683 0.91966109 0.95544073 0.96070142 0.92527027]\n",
      " [0.92761905 0.93085157 0.95487546 0.96633634 0.91971042]]\n"
     ]
    }
   ],
   "source": [
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "524c9b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99514254 0.99507922 0.99573413 0.99296016 0.9972318 ]\n",
      " [1.         1.         0.99928571 0.99856115 0.99931507]\n",
      " [0.99931507 1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44c6ed30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7NUlEQVR4nO3deXhV5bn38e+PhFFGBT3KIGBRRIqAKSLORQFnpSrOonWgDoC+aEVrD1p7alu14oioYB2OiDMqR1GQ4ggGRQRBEgEh4BBAZhkS7vePZwU2m51kB7LZGe7Pde0rWfO9p3XvZ1jPkpnhnHPOxauR7gCcc85VTJ4gnHPOJeQJwjnnXEKeIJxzziXkCcI551xCniCcc84l5AmimpBkkn4V/T9C0u3JrLsTx7lQ0oSdjbOqk7RWUtsSli+UdMLujClZu/K5cJWTJ4hKQtI7ku5MMP8MST9Iykx2X2Y2wMz+Ug4xtY5OGluPbWbPmVmvXd13McdrKOl+SYuiE21uNN00FcdLBTOrb2bzASQ9Jemund2XpP6SCqPXYrWkLyWdWn7RpoekyZI2RM+r6HHEbjz+Lr0vVYkniMrjKeBiSYqbfzHwnJkV7P6Qdh9JtYCJwCFAH6Ah0ANYDnTbif0lnVAruE/MrD7QGHgEGCOpcVojKh/XRcm06PFJWTauQu9vepmZPyrBA6gLrAKOiZnXBNgAHEo4SX4CrAS+Bx4CasWsa8Cvov+fAu6KWXZTtM1S4PK4dU8BvgBWA4uBYTHbLYrWXRs9jgD6Ax/GrNMD+CyK/TOgR8yyycBfgI+ANcAEoGkxz/8K4Eegfgmv0da4458ncByQB/wR+AF4BpgDnBqzfiawDOgaTXcHPo5e0y+B44o57mXAGzHTucDYmOnFQOfYGIGrgM3Apui1eyNavhAYAsyMXrMXgDrFHDf+ta4X7f830fQBwCRCEl0GPAc0jlm/xGOV8rloBDwN5APfAX8CasTE9RHwr+i1mx99DvpHr8VPwKUlvI+TgSsSzK8RHee7aB9PA42iZa2j+H5P+FxOieZfHr3PPwPvAPtH8xXF91P03GcCHYt7X6rrI+0B+KMMbxY8DjwRM301MCP6/7DohJYZfVnmAINj1k2YIAi/xn+Mvhx7AP8bt+5xwK+jL2enaN0zo2VFX8rMmOP0JzppAXtGX8yLo7jOj6b3ipZPBr4FDiQkwMnA3cU89zHAv0t5fUpLEAXA34Ha0fH+TCh9Fa1/CjA3+r854cR6cvTcT4ymmyU4blvCibAGsG90AlsSs+xntp08i03U0byFwDRgv+j1mwMMKOb5xr7WGcC1hBPb3tG8X0Vx1waaAVOA+5M5VhKfi6eB14EG0edgHvD7mLgKCIkzA7iLcNJ+OIqlF+EHQcJkT/EJ4nJC8m0L1AdeAZ6J+yw+HcVbFzgzWv9gwufvT8DH0fq9gemEkpeidfYt7n2prg+vYqpc/g2cI6luNH1JNA8zm25mn5pZgZktBB4Djk1in+cCo81slpmtA4bFLjSzyWb2lZltMbOZwPNJ7hfCCTfHzJ6J4noemAucFrPOaDObZ2a/AGOBzsXsay/Cr9ldsQX4bzPbGB3vf4HTJdWLll8QzQO4CBhvZuOj5/4ukE1IGNux0KawJor9WMIv1SWS2kfTH5jZljLE+YCZLTWzFcAbFP+aAHSXtJJQkrwHuMjMforiyjWzd6Pnmw/cx47vXXHHKvZzISkD6AcMNbM10eftXsIPgSILzGy0mRUSSiYtgTujWCYQEllJDd4PSFoZPT6P5l0I3Gdm881sLTAUOC+uOmmYma2L3t+rgb+Z2RwLVbD/A3SWtD+hlNAAaA8oWmdXP19VjieISsTMPiQU6c+IesL8huiEJulASW9GDdarCV+GZBpv9yMU+4t8F7tQ0uGS3peUL2kVMCDJ/Rbt+7u4ed8Rfp0X+SHm//WEX4aJLCf8Ot8V+Wa2oWjCzHIJv5pPi5LE6WxLEPsTknHRSWolcFQJMfyHUEo5Jvp/MuFkfGw0XRbJviYAn5pZY0J14zjg6KIFkvaWNEbSkugz8Sw7vnfFHaukz0VToFbcvPj39ceY/38BMLP4eSU9r4Fm1jh6dI2JKf6YmcA+MfNiY94fGB7z/q0glBaam9kkQjXsw8CPkkZKalhCPNWSJ4jK52lCyeFiYELMl+5Rwq/zdmbWELiV8GUozfeEX3dFWsUt/1/CiaelmTUCRsTst7ShgJcSvqSxWgFLkogr3ntAb0l7lLDOekI9fJH/ilueKN7nCVVfZwBfR0kDwonmmZiTVGMz28PM7i7m2EUJ4ujo//9QeoIot6GUo1/U1xA6MnSJZv8tOkan6DNxEcl9JqDkz8Uywi/w/eOW78z7Whbxn6dWhKqs2MQT+5ouBq6Oew/rmtnHAGb2gJkdRuj4cCChzSV+H9WaJ4jK52ngBOBKouqlSANCQ/LaqGrjD0nubyzQX1KH6Ff0f8ctbwCsMLMNkroRqmGK5BOqbYrr1z8eOFDSBZIyJfUDOgBvJhlbrGcIX/iXJbWXVEPSXpJulVRU7TMDuEBShqQ+JFcVNoZQJ/4HtpUeIPzaPk1S72h/dSQdJ6lFMfv5D3A8UNfM8oAPCPX4exEa+RP5keJfuzIzs+XAE4S2FQjv3VpgpaTmbDsBJqPYz0VUbTQW+KukBlGVzY2E1yyVngdukNRGUn1CKfkFK74H3whgqKRDACQ1knRO9P9votJxTWAdoYquMNquXN+XyswTRCUT1fd+TGiIGxezaAjh5L2G0Jj9QpL7+z/gfkJvl9zob6xrgDslrSGceMbGbLse+CvwUVSM7x637+XAqcD/I1QR3UzoNbQsmdji9rWRkBjnAu8SkuE0QnXH1Gi1QYT2jZWE+urXktjv94TeXz2Iec3MbDGhVHErIREuJpxgE35nzGwe4WT8QTS9mtB756PohJrIk0CH6LUrNdYk3Q+cLKkTcAfQldBL5y1Co25SkvhcXE84sc4HPiQk11G7FnqpRhF+KEwBFhBO6tcXt7KZvUrolDAmqmKbBZwULW5I+J78TKiqWk5ow4HUvC+Vksy8NOWcc25HXoJwzjmXkCcI55xzCXmCcM45l5AnCOeccwlVqQGtmjZtaq1bt053GM45V2lMnz59mZk1S7SsSiWI1q1bk52dne4wnHOu0pAUP9rBVl7F5JxzLiFPEM455xLyBOGccy4hTxDOOecS8gThnHMuoZQlCEmjJP0kaVYxyyXpgejG8zMldY1Z1kfSN9GyW1IVo3POueKlsgTxFGG44+KcBLSLHlcR7mdQdLeqh6PlHYDzJXVIYZzOOecSSNl1EGY2RVLrElY5A3jawnCyn0pqLGlfwr1lc6PbOCJpTLTu16mKdVdt2rSJNWvWbH2sXr2aNWvWsHbtWjZv3kxBQcHWR3HThYXFjQjtnHMlq1+/PjfffHO57zedF8o1Z/vbA+ZF8xLNP7y4nUi6ilACoVWr+JuhlR8zY8KECQwfPpwlS5ZsTQJr1qxh06ZN5XIMKdmbfTnn3Db77LNPlUsQic6GVsL8hMxsJDASICsrq9xvblGUGIYNG8ann35Ky5Yt6dq1Kw0bNqRBgwYlPurXr0+tWrWoWbMmmZmZWx/x05mZmdSo4f0FnHMVSzoTRB7b3/O2BeGes7WKmb9bxSeGVq1a8dhjj9G/f39q1aq1u8NxzrndLp0/W8cBl0S9mboDq6LbP34GtIvuO1sLOI/tb62ZUmbGO++8Q48ePejTpw9Lly7lscceIycnh6uuusqTg3Ou2khZCULS88BxQFNJeYSbntcEMLMRhBvan0y43+164LJoWYGk64B3gAxglJnNTlWcRbzE4Jxz20tlL6bzS1luwLXFLBtPSCAp54nBOecSq1LDfe+M1atXc+6559KoUSNGjBjBZZdd5onBOefwBEGjRo2YOHEinTp18sTgnHMxqn2CAMjKykp3CM45V+F453vnnHMJeYJwzjmXkCcI55xzCXmCcM45l5AnCOeccwl5gnDOOZeQJwjnnHMJeYJwzjmXkCcI55xzCXmCcM45l5AnCOeccwl5gnDOOZeQJwjnnHMJeYJwzjmXUEoThKQ+kr6RlCvplgTLm0h6VdJMSdMkdYxZdoOk2ZJmSXpeUp1Uxuqcc257KUsQkjKAh4GTgA7A+ZI6xK12KzDDzDoBlwDDo22bAwOBLDPrSLg39XmpitU559yOUlmC6Abkmtl8M9sEjAHOiFunAzARwMzmAq0l7RMtywTqSsoE6gFLUxirc865OKlMEM2BxTHTedG8WF8CfQEkdQP2B1qY2RLgHmAR8D2wyswmJDqIpKskZUvKzs/PL+en4Jxz1VcqE4QSzLO46buBJpJmANcDXwAFkpoQShttgP2APSRdlOggZjbSzLLMLKtZs2blFrxzzlV3qbwndR7QMma6BXHVRGa2GrgMQJKABdGjN7DAzPKjZa8APYBnUxivc865GKksQXwGtJPURlItQiPzuNgVJDWOlgFcAUyJksYioLukelHi6AnMSWGszjnn4qSsBGFmBZKuA94h9EIaZWazJQ2Ilo8ADgaellQIfA38Plo2VdJLwOdAAaHqaWSqYnXOObcjmcU3C1ReWVlZlp2dne4wnHOu0pA03cyyEi3zK6mdc84l5AnCOedcQp4gnHPOJeQJwjnnXEKeIJxzziXkCcI551xCniCcc84l5AnCOedcQp4gnHPOJeQJwjnnXEKeIJxzziXkCcI551xCniCcc84l5AnCOedcQp4gnHPOJeQJwjnnXEKeIJxzziWU0gQhqY+kbyTlSrolwfImkl6VNFPSNEkdY5Y1lvSSpLmS5kg6IpWxOuec217KEoSkDOBh4CSgA3C+pA5xq90KzDCzTsAlwPCYZcOBt82sPXAoMCdVsTrnnNtRKksQ3YBcM5tvZpuAMcAZcet0ACYCmNlcoLWkfSQ1BI4BnoyWbTKzlSmM1TnnXJxUJojmwOKY6bxoXqwvgb4AkroB+wMtgLZAPjBa0heSnpC0R6KDSLpKUrak7Pz8/PJ+Ds45V22lMkEowTyLm74baCJpBnA98AVQAGQCXYFHzawLsA7YoQ0DwMxGmlmWmWU1a9asvGJ3zrlqLzOF+84DWsZMtwCWxq5gZquBywAkCVgQPeoBeWY2NVr1JYpJEM4551IjlSWIz4B2ktpIqgWcB4yLXSHqqVQrmrwCmGJmq83sB2CxpIOiZT2Br1MYq3POuTgpK0GYWYGk64B3gAxglJnNljQgWj4COBh4WlIhIQH8PmYX1wPPRQlkPlFJwznn3O4hs/hmgcorKyvLsrOz0x2Gc85VGpKmm1lWomV+JbVzzrmEPEE455xLyBOEc865hDxBOOecS8gThHPOuYQ8QTjnnEvIE4RzzrmEPEE455xLyBOEc865hDxBOOecS8gThHPOuYQ8QTjnnEvIE4RzzrmEkkoQkurG3JvBOedcNVBqgpB0GjADeDua7ixpXIkbOedSKzcX+vaFf/873ZG4KiyZEsQwoBuwEsDMZgCtUxWQc64Uzz8PXbvC669D//5w9dWwcWO6o3JVUDIJosDMVqU8Eudcydatg8svhwsugE6dQinij3+EkSPhmGNg8eJ0R7h7rVgB//gH3HUXfPopFBSkO6IqJ5kEMUvSBUCGpHaSHgQ+TmbnkvpI+kZSrqRbEixvIulVSTMlTZPUMW55hqQvJL2Z1LNxrqqaOROysuCpp+C222DyZGjTBu6+G15+GebMCaWKSZN2/VgrVkBFvtPkokVwww3QqlVIkLffDkccAU2bhmq3Rx+FnJyK/RwqiWQSxPXAIcBG4H+BVcDg0jaSlAE8DJwEdADOl9QhbrVbgRlm1gm4BBget3wQMCeJGJ2rmszgkUegWzdYuRLefTf8Ys6MuZ18374wbRo0awYnnhh+VZf15FhQAC+9FE60e+0VTr79+8PTT0NeXnk+o5331VdwySVwwAHw0EPhec+cCfn5MGYMnH02TJ8O11wDBx4YEuiVV8LYsbBsWbqjr5zMrNgHkAG8V9I6JWx7BPBOzPRQYGjcOm8BR8VMfwvsE/3fApgI/BZ4M5ljHnbYYeYqmC1b0h1B+q1da7ZmTdm3W7HC7KyzzMCsTx+zH38sef3Vq83OOSes37ev2apVpR9j9Wqz++83a906bNe2rdmf/xz2s9deYR6YHXig2YABZmPHmuXnl/257KwtW8z+8x+zk08Oceyxh9ngwWbffVf8+vPmmT38sNmZZ5o1bBi2k8y6djX7/e/N7rrL7LnnzD7+2Oz77yvnZ/SXX8w++8zs8cfNrr3W7NJLd3pXQLYVdx4vboFtO2mPAxqVtl6C7c4GnoiZvhh4KG6d/wHui/7vBhQAh0XTLwGHAceVlCCAq4BsILtVq1Y7/SK5FMjJMWvRInxRly5NdzS7z5YtZl9+afb3v5sdd5xZZqZZjRpmHTuGE9Rjj5nNmGG2eXPx+/joI7NWrcK2//ynWWFh8se+5x6zjAyz9u3Nvv468XqLFpkNGbLtBHrUUWavvGJWULBtncLCEOd995mdcopZ/frbEsahh5rdcIPZ+PFmGzcm/dIkrbAwxNO9ezhe06Zmd95ptnx52fazeXNIBHfeaXbssWZ7773tORQ96tY1O/jgkISuvTa8fq+8Ej6/yb7updmyJbzm779vNnWq2dy54Tuxbl3pCWrZMrOJE83uvdfsoovC5ygjY1v89eubHX/8Tie6khKErJSiqKSxQHfgXWBdTMljYCnbnQP0NrMroumLgW5mdn3MOg0J1UpdgK+A9sAVQEvgZDO7RtJxwBAzO7XEQIGsrCzLzs4ubTW3OyxbFqorli2DDRugbl0YPhwuugik8j3WL7+E4xQ98vO3ny4ogN694aSToF698j12kaLqn7ffDo+lS8P8Tp2gT5/w/KdODVVBK1aEZfXqwWGHweGHh0e3btC8Ofz97/DnP4dqnjFjwvyymjwZzj03vDajR4fqF4DsbLjvvlDtAmH+jTcmd4zNm0MVzsSJoa3jo49C76nGjeGss6BfP/jtb6FmzbLHC+F0N2sWTJgAjz8O33wTqomGDAnVXeX13q1bBwsXwoIF2z+K5q2K6ZPToAF06RLad4oeBx20fRVfvC1b4Ntv4fPP4Ysvtv0trporMxMaNdrxUVgIX365feeD/fYL8XTuvO3Rti3U2PlrniVNN7OshMuSSBCXJppvZiV2wJZ0BDDMzHpH00Oj7f5WzPoCFgCdCNVRFxNKFHWAhsArZnZRScf0BFFB/PIL9OwZvhSTJoU67csvDyeUU06Bxx4LJ8KdsX59aKh95hn4/vvwpVu3LvG6Ujj25s3hS1+vXkgSv/tdiKNhw51+imzZEp7f22/D//1f6EVTWBi+2L16haTQu/eOz9MsnDyKksXUqWE/mzaF5Q0awJo14WT72GNhfzsrLw/OOSfEduWV4YQ7ZUo4xpVXwsCBsP/+O7//DRvC+/vCC/Daa7B6dXi9f/e7EP+xx0JGRsn7+OEHeO+9kBTeey+8pxAS5003hX2VdDJOhZ9/Du/Rl19uO7nPmBE+1xCS/aGHbksc7duH9YuSwYwZ4T2EkCw7dtx+3Q0bwuextIcZ/PrXIQl06RKOuffe5f50dylBRDuoBRwYTX5jZpuT2CYTmAf0BJYAnwEXmNnsmHUaA+vNbJOkK4GjzeySuP0ch5cgKo/CwvDL9dVX4cUXwxe8aP5DD8HQoVCrFvzrX+FXYbKlifz8sP3DD8Py5eHL1rFj6LnStGlooC36v+jRpEk4QRUUhBPjyy/DK6+Ek1KtWuEE/rvfwemnh3WLs2JFaCCdOTM8vvoq/NItSkyHHRYSwkknhZJAWU9oGzeG/U6dGk4wxx4bGmPLo6S1cWMoITzySCiRDBoEV1yxa8kxkQ0bQrJ84QV4443w2uyzTyihnHce9OgRfuX+8gt88EEobU2YEJ43hMRywgkhuZ54IrRsWb7x7aqCApg3L7w/RY8vvghJsUi9euEk3rXrtoRwyCHhs1aBlZQgkmlLOA74DvgPMIXwK/+Y0raLtj2ZkCS+BW6L5g0ABti2huwcYC7wCtCkmON7I3VlccMNoV70X/9KvDwnx+yYY7Y1vC5aVPL+5s0zu/pqszp1wjann272wQc737BYWBi2HzzYrGXLsM/MTLNevULbQHa22bPPmt18s9lJJ5k1b759ffVee4X63kGDzJ55pvSG44pi7tyS2zzK07p1oTH7d7/b9r41bx5et9q1w3StWmH6b38Lr3l51fXvToWF4fP85puhrSe2/aYSYRcbqacDB8VMHwhML227dDw8QaTZ/feHj9SgQSWvV1ho9tBDoUdKgwZmI0fueML/6KPQg0cKJ5UrrwwnufK0ZUtoMLz5ZrMDDtg+EdSqFRpiL744NBK//XZoVKyMPV7SafXq0GPotNPMOnfe1rC9dm26I3ORkhJEMm0QMy1cp1DivIrAq5jS6JVXQnXCWWeFBtDS6p4hNAhecUWoxz7xxFDnPmMG3HMPfPwx7Lln6NN+3XWhuiKVzEJ1x7x50KFD6Ee/s42tzlUiu9pIPQow4Jlo1oVAppldVq5RlgNPEGnyySeh90rnzuFkX7du8tuahaEihgyBtWvDvDZtQr35ZZfBHnukJGTnXLCrCaI2cC1wFCBCO8QjZlbhRgfzBJEGOTmhO2uTJuFXf7NmO7ef776DBx8M3S379t39PVecq6Z2NUHsAWwws8JoOgOobWbryz3SXeQJooy2bAlVKp98ErpCZmSEnj2//W3oClma/PzQO2XlyrCPX/0q5SE758pXSQkimZ9pE4ETgKj8T11gAtCjfMJzu83q1aEr5SefhMfUqaHPN4SLnQoKwkBnNWvCUUeFbpt9+oTupPFdLn/5JXQPzcsL1UqeHJyrcpJJEHXMrCg5YGZrJaXoclRXrhYvDhcfFSWE2bNDnb8U+meffXaoHurePVwdWlAQLmYruvjr5pvDo3nzbf38TzgB6teHCy8MCaZogDfnXJWTTBXTR8D1ZvZ5NH0YYUylCndW8ComwpWoL74YLlj6OBqVvUmTkAS6dw8n827dkrtCd8mSbUNHvPtuuLozIyOMpjlvHtx/f7jwyjlXae1qG8RvgDFANLgM+wL9zGx6uUZZDqptgvjpp3CV8AsvhCuGiy7R79cvdDtt336XxmoBQuni009DspgwIVzxetdd5RO/cy5tymOojZrAQYReTHMtiaE20qFaJYgVK8JwFi+8ENoACgtDIujXLzwOPjjdETrnKoFdaqSORmV928xmSfoTcIeku4qqnNxulJ8Pb74Z6v0nTAi/6g84INxVq1+/UGoo75FSnXPVVjKN1Leb2YuSjgJ6A/cAjwKHpzQyFyxYEEbKfO01+PDD0DW1Vatwy8V+/cKAYJ4UnHMpkEyCKIz+ngI8amavSxqWupCquaIhH159NSSFL78M83/963Av4rPOClcse1JwzqVYMgliiaTHCNdC/D26snoXWzzdDj78MDQ0v/ZauHGJBEceCffeC2ecEaqSnHNuN0omQZwL9AHuMbOVkvYFbkptWNXMs8/CxRdD7drhOoM//QlOOy0lNwdxzrlklZogoiE1XomZ/h74PpVBVStm8M9/hquVP/44uSEunHNuN/AR0dJtypTQ5vD4454cnHMVirclpNvw4eG+BxdemO5InHNuOylNEJL6SPpGUq6kWxIsbyLpVUkzJU2T1DGa31LS+5LmSJotqWqO57BwIbz+Olx1VdnuoeCcc7tBsVVMktYQbhS0wyLAzKzEu55Hw4I/DJwI5AGfSRpnZl/HrHYrMMPMzpLUPlq/J1AA/D8z+1xSA2C6pHfjtq38Hn449Fa65pp0R+KcczsoNkGY2a5WiHcDcs1sPoCkMcAZQOxJvgPwt+h4cyW1lrRPbEO4ma2RNAdoHrdt5bZuHTzxRLg5TsuW6Y7GOed2UGwVk6Q9S3okse/mwOKY6bxoXqwvgb7R8boB+wMt4uJoDXQBphYT51WSsiVl5+fnJxFWBfHMM+FGOz4aqnOugiqpF9N0QhVTokt2DWhbyr6L2y7W3cBwSTOAr4AvCNVLYQdSfeBlYLCZrU50EDMbCYyEMFhfKTFVDGbwwANhmIweft8l51zFVFIVU5td3HceEFt30oJtQ4YXHWM1cBmAJAELokfRCLIvA8+Z2StUJe+9B3PmwL//7UNmOOcqrKSug5DUBGgH1CmaZ2ZTStnsM6CdpDbAEuA84IK4/TYG1pvZJuAKYIqZrY6SxZPAHDO7L8nnUnk88EC4Srpfv3RH4pxzxUpmuO8rgEGEEsAMoDvwCfDbkrYzswJJ1wHvABnAKDObLWlAtHwEcDDwtKRCQgP076PNjwQuBr6Kqp8AbjWz8WV6dhVRbi689RbcfnsYWsM55yqoZEoQg4DfAJ+a2fFRd9Q7ktl5dEIfHzdvRMz/nxBKJvHbfUjiNozK76GHIDMTBgxIdyTOOVeiZC6U22BmGwAk1TazuYS7y7myWr0aRo2Cc8+FffdNdzTOOVeiZEoQeVFbwWvAu5J+Jq6x2SXp3/+GNWtg4MB0R+Kcc6VKZjTXs6J/h0l6H2gEvJ3SqKqiLVvgwQehe3fo1i3d0TjnXKlKrWKS1D0a7gIz+w/wPuHCNVcWb78NOTleenDOVRrJtEE8CqyNmV4XzXNlMXw47LcfnH12uiNxzrmkJJMgZGZbr1A2sy34fSTKZs4cmDAB/vAHqFkz3dE451xSkkkQ8yUNlFQzegwC5qc6sCrlwQfDNQ9XX53uSJxzLmnJJIgBQA/C1dB5wOHAVakMqkpZuTL0Xjr/fGjWLN3ROOdc0pLpxfQTYZgMtzOefBLWr/fGaedcpZNML6YDJU2UNCua7iTpT6kPrQooLAxXTh99NHTxjl/OucolmSqmx4GhwGYAM5tJdS5RTJoE774bxlTatKnkdd94I9xW1O/54JyrhJLpjVTPzKZp+2GpC4pbuUpbuhR69tw2LUHz5tC6NbRps+Pf4cOhVSs444w0BeycczsvmQSxTNIBRDf7kXQ20e1Aq51vvgl/770X9twzlA4WLAh/J0+GJUvCFdOx/v73MDifc85VMsmcua4l3LGtvaQlhBv6XJjSqCqq3Nzw9+yzQ8kg3qZNkJe3LWksXw7XXrtbQ3TOufKSTC+m+cAJkvYgtFn8AvQDvktxbBVPTk64nqFFi8TLa9WCtm3DwznnKrliG6klNZQ0VNJDkk4E1gOXArnAubsrwAolNzec/Gsk07bvnHOVW0kliGeAnwl3j7sSuBmoBZxpZjNSH1oFlJsL7Xa4v5FzzlVJJf0Ubmtm/c3sMeB8IAs4tSzJQVIfSd9IypV0S4LlTSS9KmmmpGmSOia77W63ZUtIEL/6Vbojcc653aKkBLG56B8zKwQWmNmaZHcsKQN4GDgJ6ACcL6lD3Gq3AjPMrBNwCTC8DNvuXt9/D7/84iUI51y1UVKCOFTS6uixBuhU9L+k1UnsuxuQa2bzzWwTMAaIvyCgAzARILqVaWtJ+yS57e6VkxP+egnCOVdNFJsgzCzDzBpGjwZmlhnzf8Mk9t0cWBwznRfNi/Ul0BdAUjdgf6BFktsSbXeVpGxJ2fn5+UmEtZOKurh6gnDOVROp7I6jBPMsbvpuoImkGcD1wBeEq7ST2TbMNBtpZllmltUslaOl5uaGbqwtW6buGM45V4Gk8hLfPCD2bNoCWBq7gpmtBi4DUBjLY0H0qFfatrtdTk7o4pqRkdYwnHNud0llCeIzoJ2kNpJqEQb4Gxe7gqTG0TKAK4ApUdIoddvdznswOeeqmZSVIMysQNJ1wDtABjDKzGZLGhAtHwEcDDwtqRD4Gvh9SdumKtZSmYUEETtQn3POVXEpHUXOzMYD4+PmjYj5/xMgYb/RRNumzfffh5v+eAnCOVeN+JgRyfAeTM65asgTRDKKEoRfJOecq0Y8QSQjJwdq1vQurs65asUTRDKKRnH1G/8456oRTxDJyMnx9gfnXLXjCaI0RV1cPUE456oZTxCl+fFHWLfOG6idc9WOJ4jS+CiuzrlqyhNEafwaCOdcNeUJojS5uaH30v77pzsS55zbrTxBlCYnB9q08S6uzrlqxxNEabwHk3OumvIEUZKiLq7eg8k5Vw15gijJTz/BmjVegnDOVUueIEriPZicc9WYJ4iSFF0D4VVMzrlqKKUJQlIfSd9IypV0S4LljSS9IelLSbMlXRaz7IZo3ixJz0uqk8pYE8rNDfeg9i6uzrlqKGUJQlIG8DBwEtABOF9Sh7jVrgW+NrNDgeOAeyXVktQcGAhkmVlHwm1Hz0tVrMXKzQ1dXGvW3O2Hds65dEtlCaIbkGtm881sEzAGOCNuHQMaSBJQH1gBFETLMoG6kjKBesDSFMaamI/i6pyrxlKZIJoDi2Om86J5sR4CDiac/L8CBpnZFjNbAtwDLAK+B1aZ2YQUxrojH8XVOVfNpTJBKME8i5vuDcwA9gM6Aw9JaiipCaG00SZatoekixIeRLpKUrak7Pz8/PKKHZYtg9WrvYHaOVdtpTJB5AGx9+hswY7VRJcBr1iQCywA2gMnAAvMLN/MNgOvAD0SHcTMRppZlpllNWvWrPyi91FcnXPVXCoTxGdAO0ltJNUiNDKPi1tnEdATQNI+wEHA/Gh+d0n1ovaJnsCcFMa6I78GwjlXzaVsBDozK5B0HfAOoRfSKDObLWlAtHwE8BfgKUlfEaqk/mhmy4Blkl4CPic0Wn8BjExVrAkVdXFt3Xq3HtY55yqKlA5RambjgfFx80bE/L8U6FXMtv8N/Hcq4ytRTk64/qFWrbSF4Jxz6eRXUhfHezA556o5TxCJmIUShPdgcs5VY54gElm+HFat8hKEc65a8wSRiPdgcs45TxAJ+SiuzjnnCSKh3FyoUSMM1Oecc9WUJ4hEcnO9i6tzrtrzBJGIj+LqnHOeIBLyayCccy61V1JXSitWwM8/ewO1cyXYvHkzeXl5bNiwId2huCTVqVOHFi1aULMMN0DzBBHPR3F1rlR5eXk0aNCA1q1bE8bTdBWZmbF8+XLy8vJoU4bON17FFM+vgXCuVBs2bGCvvfby5FBJSGKvvfYqc4nPE0S8nByQoG3bdEfiXIXmyaFy2Zn3yxNEvNxcaNUKatdOdyTOOZdWniDieQ8m5yq85cuX07lzZzp37sx//dd/0bx5863TmzZtKnHb7OxsBg4cWOoxevRIeBPLasUbqePl5MC556Y7CudcCfbaay9mzJgBwLBhw6hfvz5DhgzZurygoIDMzMSnt6ysLLKysko9xscff1wusZa3kp5befMEEWvFivDwEoRzSRs8ePDWk3V56dy5M/fff3+Ztunfvz977rknX3zxBV27dqVfv34MHjyYX375hbp16zJ69GgOOuggJk+ezD333MObb77JsGHDWLRoEfPnz2fRokUMHjx4a+mifv36rF27lsmTJzNs2DCaNm3KrFmzOOyww3j22WeRxPjx47nxxhtp2rQpXbt2Zf78+bz55pvbxTV79mwuu+wyNm3axJYtW3j55Zdp164dTz/9NPfccw+S6NSpE8888wzfffcdl19+Ofn5+TRr1ozRo0fTqlWrHZ7bNddcw7XXXkt+fj716tXj8ccfp3379rz44ovccccdZGRk0KhRI6ZMmbJL70NKE4SkPsBwwi1HnzCzu+OWNwKeBVpFsdxjZqOjZY2BJ4COgAGXm9knqYyXb78Nfz1BOFcpzZs3j/fee4+MjAxWr17NlClTyMzM5L333uPWW2/l5Zdf3mGbuXPn8v7777NmzRoOOugg/vCHP+xwrcAXX3zB7Nmz2W+//TjyyCP56KOPyMrK4uqrr2bKlCm0adOG888/P2FMI0aMYNCgQVx44YVs2rSJwsJCZs+ezV//+lc++ugjmjZtyooVKwC47rrruOSSS7j00ksZNWoUAwcO5LXXXtvhufXs2ZMRI0bQrl07pk6dyjXXXMOkSZO48847eeedd2jevDkrV67c5dczZQlCUgbwMHAikAd8JmmcmX0ds9q1wNdmdpqkZsA3kp4zs02ExPK2mZ0tqRZQL1WxbuWjuDpXZmX9pZ9K55xzDhkZGQCsWrWKSy+9lJycHCSxefPmhNuccsop1K5dm9q1a7P33nvz448/0qJFi+3W6dat29Z5nTt3ZuHChdSvX5+2bdtuva7g/PPPZ+TIkTvs/4gjjuCvf/0reXl59O3bl3bt2jFp0iTOPvtsmjZtCsCee+4JwCeffMIrr7wCwMUXX8zNN9+8w3Nbu3YtH3/8Meecc87WZRs3bgTgyCOPpH///px77rn07du37C9gnFQ2UncDcs1sfnTCHwOcEbeOAQ0U+l/VB1YABZIaAscATwKY2SYzW5nCWIPcXO/i6lwltscee2z9//bbb+f4449n1qxZvPHGG8VeA1A7psdiRkYGBQUFSa1jZknFdMEFFzBu3Djq1q1L7969mTRpEmaWVLfT2HWKntuWLVto3LgxM2bM2PqYM2cOEEord911F4sXL6Zz584sX748qRiLk8oE0RxYHDOdF82L9RBwMLAU+AoYZGZbgLZAPjBa0heSnpC0BwlIukpStqTs/Pz8XYs4NxdatoQ6dXZtP865tFu1ahXNm4dTzlNPPVXu+2/fvj3z589n4cKFALzwwgsJ15s/fz5t27Zl4MCBnH766cycOZOePXsyduzYrSfwoiqmHj16MGbMGACee+45jjrqqB3217BhQ9q0acOLL74IhKukv/zySwC+/fZbDj/8cO68806aNm3K4sWLd9i+LFKZIBKlx/iU2xuYAewHdAYeikoPmUBX4FEz6wKsA25JdBAzG2lmWWaW1axZs12L2Edxda7KuPnmmxk6dChHHnkkhYWF5b7/unXr8sgjj9CnTx+OOuoo9tlnHxo1arTDei+88AIdO3akc+fOzJ07l0suuYRDDjmE2267jWOPPZZDDz2UG2+8EYAHHniA0aNHb220Hj58eMJjP/fcczz55JMceuihHHLIIbz++usA3HTTTfz617+mY8eOHHPMMRx66KG79ByVbDGpzDuWjgCGmVnvaHoogJn9LWadt4C7zeyDaHoSIREsAj41s9bR/KOBW8zslJKOmZWVZdnZ2TsfdLNm0LcvPPbYzu/DuWpgzpw5HHzwwekOI+3Wrl1L/fr1MTOuvfZa2rVrxw033JDusIqV6H2TNN3MEvb7TWUJ4jOgnaQ2USPzecC4uHUWAT2jIPcBDgLmm9kPwGJJB0Xr9QS+JpVWroRly7yB2jmXtMcff5zOnTtzyCGHsGrVKq6++up0h1SuUtaLycwKJF0HvEPo5jrKzGZLGhAtHwH8BXhK0leEKqk/mtmyaBfXA89FyWU+cFmqYgV8kD7nXJndcMMNFbrEsKtSeh2EmY0HxsfNGxHz/1KgVzHbzgBKv9yxvHiCcM657fhYTEWKroE44ID0xuGccxWEJ4giubnQogXUrZvuSJxzrkLwBFHER3F1zrnt+GB9RXJy4Mwz0x2Fcy4Jy5cvp2fPngD88MMPZGRkUHQd1LRp06hVq1aJ20+ePJlatWptHdJ7xIgR1KtXj0suuSS1gVcyniAAVq2C/HwvQThXSZQ23HdpJk+eTP369bcmiAEDBqQizF1mZpgZNWqkp7LHEwRs68Hk10A4V3aDB0M5D/dN585QxkEAp0+fzo033sjatWtp2rQpTz31FPvuuy8PPPAAI0aMIDMzkw4dOnD33XczYsQIMjIyePbZZ3nwwQeZOHHi1iRz3HHHcfjhh/P++++zcuVKnnzySY4++mjWr19P//79mTt3LgcffDALFy7k4Ycf3uHeErfccgvjxo0jMzOTXr16cc899/Djjz8yYMAA5s+fD8Cjjz5Kjx49uO+++xg1ahQAV1xxBYMHD2bhwoWcdNJJHH/88XzyySe89tprjB07lrFjx7Jx40bOOuss7rjjDtatW8e5555LXl4ehYWF3H777fTr1688Xv2tPEGAd3F1rpIzM66//npef/11mjVrxgsvvMBtt93GqFGjuPvuu1mwYAG1a9dm5cqVNG7cmAEDBmxX6pg4ceJ2+ysoKGDatGmMHz+eO+64g/fee49HHnmEJk2aMHPmTGbNmkXnzp13iGPFihW8+uqrzJ07F0lbh9weOHAgxx57LK+++iqFhYWsXbuW6dOnM3r0aKZOnYqZcfjhh3PsscfSpEkTvvnmG0aPHs0jjzzChAkTyMnJYdq0aZgZp59+OlOmTCE/P5/99tuPt956CwhjT5U3TxCwLUF4F1fnyq4CDPe9ceNGZs2axYknnghAYWEh++67LwCdOnXiwgsv5Mwzz+TMJNsZi4bKPuyww7YOxvfhhx8yaNAgADp27EinTp122K5hw4bUqVOHK664glNOOYVTTz0VgEmTJvH0008DbL2Zz4cffshZZ521dZTWvn378sEHH3D66aez//770717dwAmTJjAhAkT6NKlCxCG98jJyeHoo49myJAh/PGPf+TUU0/l6KOPLuvLVipPEBAaqJs3h3qpv+WEc678mRmHHHIIn3yy4z3F3nrrLaZMmcK4ceP4y1/+wuzZs0vdX9Hw3rHDfyczbl1mZibTpk1j4sSJjBkzhoceeohJkyYVG3NxYoctNzOGDh2acBiP6dOnM378eIYOHUqvXr3485//XGqMZeHdXMG7uDpXydWuXZv8/PytCWLz5s3Mnj2bLVu2sHjxYo4//nj+8Y9/sHLlStauXUuDBg1Ys2ZNmY5x1FFHMXbsWAC+/vprvvrqqx3WWbt2LatWreLkk0/m/vvv39qQ3rNnTx599FEglG5Wr17NMcccw2uvvcb69etZt24dr776asJSQO/evRk1ahRr164FYMmSJfz0008sXbqUevXqcdFFFzFkyBA+//zzMj2fZHgJAkKCiIqCzrnKp0aNGrz00ksMHDiQVatWUVBQwODBgznwwAO56KKLWLVqFWbGDTfcQOPGjTnttNM4++yzef3113nwwQeTOsY111zDpZdeSqdOnejSpQudOnXaYXjvNWvWcMYZZ7BhwwbMjH/9618ADB8+nKuuuoonn3ySjIwMHn30UY444gj69+9Pt27dgNBI3aVLl61VWkV69erFnDlzOOKII4Bwr+xnn32W3NxcbrrpJmrUqEHNmjW3JqDylLLhvtNhp4b7LiyEyy6DXr3gootSE5hzVUx1HO67sLCQzZs3U6dOHb799lt69uzJvHnzSr3moiIp63DfXoLIyICo8cg554qzfv16jj/+eDZv3oyZ8eijj1aq5LAzPEE451wSGjRowC7dkKwS8kZq59xOqUrV09XBzrxfniCcc2VWp04dli9f7kmikjAzli9fTp06dcq0nVcxOefKrEWLFuTl5ZGfn5/uUFyS6tSpQ4sWLcq0TUoThKQ+wHDCLUefMLO745Y3Ap4FWkWx3GNmo2OWZwDZwBIz836ozlUQNWvWpE2bNukOw6VYyqqYopP7w8BJQAfgfEkd4la7FvjazA4FjgPuje5BXWQQMCdVMTrnnCteKtsgugG5ZjbfzDYBY4Az4tYxoIEkAfWBFUABgKQWwCnAEymM0TnnXDFSmSCaA4tjpvOiebEeAg4GlgJfAYPMbEu07H7gZmALJZB0laRsSdleH+qcc+UnlW0QSjAvvstDb2AG8FvgAOBdSR8AxwA/mdl0SceVdBAzGwmMBJCUL+m7mMVNgWU7E3waVKZYoXLFW5lihcoVb2WKFSpXvLsr1v2LW5DKBJEHtIyZbkEoKcS6DLjbQl+5XEkLgPbAkcDpkk4G6gANJT1rZiWOhWFmzWKnJWUXdwl5RVOZYoXKFW9lihUqV7yVKVaoXPFWhFhTWcX0GdBOUpuo4fk8YFzcOouAngCS9gEOAuab2VAza2FmraPtJpWWHJxzzpWvlJUgzKxA0nXAO4RurqPMbLakAdHyEcBfgKckfUWokvqjmVWW4p9zzlVpKb0OwszGA+Pj5o2I+X8p0KuUfUwGJu9kCCN3crt0qEyxQuWKtzLFCpUr3soUK1SueNMea5Ua7ts551z58bGYnHPOJeQJwjnnXEJVMkFI6iPpG0m5km5JdzzxJLWU9L6kOZJmSxoUzd9T0ruScqK/TdIdaxFJGZK+kPRmNF2RY20s6SVJc6PX+IiKGq+kG6LPwCxJz0uqU5FilTRK0k+SZsXMKzY+SUOj7903knpXgFj/GX0OZkp6VVLjihBrcfHGLBsiySQ1jZm32+OtcgkiyTGg0q0A+H9mdjDQHbg2ivEWYKKZtQMmRtMVRfy4WBU51uHA22bWHjiUEHeFi1dSc2AgkGVmHQm9/c6jYsX6FNAnbl7C+KLP8HnAIdE2j0Tfx93lKXaM9V2go5l1AuYBQ6FCxAqJ40VSS+BEwmUARfPSEm+VSxAkNwZUWpnZ92b2efT/GsIJrDkhzn9Hq/0bODMtAcYpZlysihprQ8KV+E8CmNkmM1tJBY2X0JOwrqRMoB7hYtIKE6uZTSGMkRaruPjOAMaY2UYzWwDkEr6Pu0WiWM1sgpkVRJOfEi7YTXusUWyJXluAfxGGGYrtQZSWeKtigkhmDKgKQ1JroAswFdjHzL6HkESAvdMYWqz72XFcrIoaa1sgHxgdVYk9IWkPKmC8ZrYEuIfwS/F7YJWZTaACxhqnuPgq+nfvcuD/ov8rZKySTifc3uDLuEVpibcqJohkxoCqECTVB14GBpvZ6nTHk4ikU4nGxUp3LEnKBLoCj5pZF2AdFaA6KZGo7v4MoA2wH7CHpMo8YkCF/e5Juo1Qtftc0awEq6U1Vkn1gNuAPydanGBeyuOtigkimTGg0k5STUJyeM7MXolm/yhp32j5vsBP6YovRtG4WAsJ1XW/lfQsFTNWCO9/nplNjaZfIiSMihjvCcACM8s3s83AK0APKmassYqLr0J+9yRdCpwKXGjbLvyqiLEeQPix8GX0fWsBfC7pv0hTvFUxQSQzBlRaSRKhjnyOmd0Xs2gccGn0/6XA67s7tngljItV4WIFMLMfgMWSDopm9QS+pmLGuwjoLqle9JnoSWiPqoixxiouvnHAeZJqS2oDtAOmpSG+rRTuavlH4HQzWx+zqMLFamZfmdneZtY6+r7lAV2jz3R64jWzKvcATib0WPgWuC3d8SSI7yhC8XAmYbjzGVHMexF6heREf/dMd6xxcR8HvBn9X2FjBToTblU7E3gNaFJR4wXuAOYCs4BngNoVKVbgeUL7yGbCCev3JcVHqCL5FvgGOKkCxJpLqLsv+p6NqAixFhdv3PKFQNN0xutDbTjnnEuoKlYxOeecKweeIJxzziXkCcI551xCniCcc84l5AnCOedcQp4gXJUQjXx5b8z0EEnDymnfT0k6uzz2VcpxzolGn30/bn5rSRek+vjOxfME4aqKjUDf2OGRK4Iyjrj5e+AaMzs+bn5rIGGCiAb5cy4lPEG4qqKAcA/fG+IXxJcAJK2N/h4n6T+SxkqaJ+luSRdKmibpK0kHxOzmBEkfROudGm2fEd1v4LPofgNXx+z3fUn/C3yVIJ7zo/3PkvT3aN6fCRdQjpD0z7hN7gaOljRD4f4R/SW9KOkNYIKkPaJ7C3wWDVB4Rinx7StpSrS/WZKO3snX3FVx/uvDVSUPAzMl/aMM2xwKHEwYdnk+8ISZdVO4idP1wOBovdbAsYTxct6X9CvgEsIIrL+RVBv4SNKEaP1uhPsQLIg9mKT9gL8DhwE/E07wZ5rZnZJ+Cwwxs+y4GG+J5hclpv7AEUAnM1sh6X8IQ6BcrnBDnGmS3gMuLCa+vsA7ZvbXqIRTrwyvl6tGPEG4KsPMVkt6mnATnl+S3Owzi4aulvQtUHSC/wqIreoZa2ZbgBxJ84H2QC+gU0zppBFhjJxNwLT45BD5DTDZzPKjYz5HuH/Fa0nGW+RdMyu6l0AvwoCKQ6LpOkCrEuL7DBgVDRj5mpnNKOOxXTXhCcJVNfcDnwOjY+YVEFWnRoPi1YpZtjHm/y0x01vY/vsRPyaNEYZgvt7M3oldIOk4wjDjiSQatnlnxO5fwO/M7Ju4OBLGFy07hnATqGck/dPMni6nuFwV4m0QrkqJflWPJTT4FllIqNKBcP+Fmjux63Mk1YjaJdoSBkx7B/hD9EscSQcq3JyoJFOBYyU1jap3zgf+U8o2a4AGJSx/B7g+SghI6hIzf4f4JO1PuMfH44RRhbuWcnxXTXkJwlVF9wLXxUw/DrwuaRph9NHift2X5BvCiXwfYICZbZD0BKFt4vPo5JxPKbcHNbPvJQ0F3if88h9vZqUN5z0TKJD0JeE+xj/HLf8LoeQ0M4pjIeH+B8XFdxxwk6TNwFpCW4pzO/DRXJ1zziXkVUzOOecS8gThnHMuIU8QzjnnEvIE4ZxzLiFPEM455xLyBOGccy4hTxDOOecS+v/J46Hw9Z9mwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mean = np.mean(train_score, axis=1)\n",
    "test_mean = np.mean(test_score, axis=1)\n",
    "\n",
    "train_std = np.std(train_score, axis=1)\n",
    "test_std = np.std(test_score, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, label = \"Training scores\", color ='black')\n",
    "plt.plot(param_range, test_mean, label = \"Testing scores\", color ='red')\n",
    "\n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Recall score\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbbc1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08acce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bf3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b4751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc249936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
